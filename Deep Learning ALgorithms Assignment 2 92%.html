<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head></head><body>






















    
    
    
    

  <div class="border-box-sizing">
    <div class="container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1>SIT744 Assignment 2: Transfer learning and Efficient Training of Deep Learning Models<a rel="noopener" class="anchor-link" href="#SIT744-Assignment-2:-Transfer-learning-and-Efficient-Training-of-Deep-Learning-Models">&#182;</a></h1><div class="alert-info">
    <p>Due: <strong>8:00pm 17 May 2021</strong>  (Monday)</p>

This is an <strong>individual</strong> assignment. It contributes <strong>45%</strong> to your final mark. Read the assignment instruction carefully.

<h2> What to submit </h2>

<p>
This assignment is to be completed individually and submitted to CloudDeakin. <strong>By the due date, you are required to submit the following files to the corresponding Assignment (Dropbox) in CloudDeakin</strong>:

<ol>
<li>    <strong>[YourID]_assignment2_solution.ipynp</strong>:  This is your Python notebook solution source file. </li>
<li>    <strong>[YourID]_assingment2_output.html</strong>: This is the output of your Python notebook solution exported in HTML format.</li>
<li>    Extra files needed to complete your assignment, if any (e.g., images used in your answers).</li>
</ol>
</p>

<p>
For example, if your student ID is: 123456, you will then need to submit the following files:
<ul>
<li> 123456_assignment2_solution.ipynp </li>
<li> 123456_assignment2_output.html</li>
</ul>
</p>

<h2> Warning </h2>

Some components of this assignment may involve heavy computation that runs for a long duration. Please start early to avoid missing the assignment due date.

<h2> Marking criteria </h2>

<p>
Your submission will be marked using the following criteria.

<ul>
<li> Showing good effort through completed tasks.</li>
<li> Applying deep learning theory to design suitable deep learning solutions for the tasks.</li>
<li> Critically evaluating and reflecting on the pros and cons of various design decisions.</li>
<li> Demonstrating creativity and resourcefulness in providing unique individual solutions.</li>
<li> Showing attention to details through a good quality assignment report.</li>
</ul>
</p>

<p>
Indicative weights of various tasks are provided, but the assignment will be marked by the overall quality per the above criteria.
</p>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Assignment objective<a rel="noopener" class="anchor-link" href="#Assignment-objective">&#182;</a></h2><p>This assignment is to feedback on your learning in deep learning theory and its application to  data analytics or artificial intelligence problems.</p>
<p>It builds on Assignment 1 but requires a higher level of mastery of deep learning theory and programming/engineering skills. In particular, you will experience training a much deeper network on a large-scale dataset. You will encounter  practical issues that help you consolidate textbook learning.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 1 Solving Fashion-MNIST with Convolutional Neural Networks<a rel="noopener" class="anchor-link" href="#Task-1-Solving-Fashion-MNIST-with-Convolutional-Neural-Networks">&#182;</a></h2><p><em>(weight ~15%)</em></p>
<p>In Assignment 1, you tackled the image classification problem in Fashion-MNIST. There, you used a Densely Connected Neural Network. You should now know that is not an optimal model architecture for the problem. In Assignment 2, you will apply the best practices of deep-learning computer vision to achieve better image classification performance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 1.1 Revisit Fashion-MNIST classification with DNN<a rel="noopener" class="anchor-link" href="#Task-1.1-Revisit-Fashion-MNIST-classification-with-DNN">&#182;</a></h3><p><em>(weight ~1%)</em></p>
<p>Review your Assignment 1 solution, and reproduce the experiment here. Try to improve the model without changing the model architecture.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">Assignment 1 model | <font color="#90AEE9">Import and Data Load</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">pyplot</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="o">%</span><span class="k">tensorflow_version</span> 2.x
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>


<span class="n">fashion_mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>2.4.1
2.4.0
0
255
(60000, 28, 28)
(10000, 28, 28)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">Assignment 1 model | <font color="#90AEE9">Preprocessing</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Max value in the image set:</span>
<span class="nb">max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>

<span class="c1"># Convert images from shape of 28*28 to 784 pixel (from a square 28x28 to a single row of 784x1)</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>

<span class="c1">#Normalization:</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>

<span class="c1">#Labels to cathegorical</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="k">import</span> <span class="n">to_categorical</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">Assignment 1 model | <font color="#90AEE9">Validation Split</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">train_images</span><span class="p">,</span> <span class="n">val_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span> <span class="c1"># 0.25 x 0.8 = 0.2</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">Assignment 1 model | <font color="#90AEE9">Training</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>
<p>The batch size = 128 and number of epoches = 50 will be used in all future experiment for better comparison of the models.</p>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># model:</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>                       
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="p">)),</span> 
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>       
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">),</span>  
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>     
<span class="p">])</span>                                                     


<span class="c1"># compile:</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>



<span class="c1"># save the initial weights for later experiments</span>
<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="c1"># fit</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">))</span>


<span class="c1"># test accuracy/loss</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;test_loss: </span><span class="si">{test_loss}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;test_acc: </span><span class="si">{test_acc}</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="c1"># model structure</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="k">import</span> <span class="n">plot_model</span>
<span class="n">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
352/352 [==============================] - 3s 5ms/step - loss: 0.8533 - accuracy: 0.7283 - val_loss: 0.5143 - val_accuracy: 0.8176
Epoch 2/50
352/352 [==============================] - 1s 4ms/step - loss: 0.5172 - accuracy: 0.8209 - val_loss: 0.3837 - val_accuracy: 0.8621
Epoch 3/50
352/352 [==============================] - 1s 4ms/step - loss: 0.4501 - accuracy: 0.8402 - val_loss: 0.3844 - val_accuracy: 0.8631
Epoch 4/50
352/352 [==============================] - 1s 4ms/step - loss: 0.4105 - accuracy: 0.8508 - val_loss: 0.3571 - val_accuracy: 0.8735
Epoch 5/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.8592 - val_loss: 0.3599 - val_accuracy: 0.8709
Epoch 6/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3796 - accuracy: 0.8630 - val_loss: 0.3392 - val_accuracy: 0.8800
Epoch 7/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3631 - accuracy: 0.8702 - val_loss: 0.3418 - val_accuracy: 0.8799
Epoch 8/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3575 - accuracy: 0.8722 - val_loss: 0.3291 - val_accuracy: 0.8848
Epoch 9/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3490 - accuracy: 0.8731 - val_loss: 0.3307 - val_accuracy: 0.8840
Epoch 10/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3355 - accuracy: 0.8792 - val_loss: 0.3357 - val_accuracy: 0.8807
Epoch 11/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3263 - accuracy: 0.8840 - val_loss: 0.3187 - val_accuracy: 0.8899
Epoch 12/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.8843 - val_loss: 0.3109 - val_accuracy: 0.8916
Epoch 13/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3163 - accuracy: 0.8844 - val_loss: 0.3237 - val_accuracy: 0.8892
Epoch 14/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3204 - accuracy: 0.8841 - val_loss: 0.3417 - val_accuracy: 0.8804
Epoch 15/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3174 - accuracy: 0.8845 - val_loss: 0.3284 - val_accuracy: 0.8884
Epoch 16/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3111 - accuracy: 0.8873 - val_loss: 0.3186 - val_accuracy: 0.8911
Epoch 17/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3069 - accuracy: 0.8905 - val_loss: 0.3151 - val_accuracy: 0.8910
Epoch 18/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3016 - accuracy: 0.8898 - val_loss: 0.3205 - val_accuracy: 0.8923
Epoch 19/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3052 - accuracy: 0.8893 - val_loss: 0.3201 - val_accuracy: 0.8898
Epoch 20/50
352/352 [==============================] - 1s 4ms/step - loss: 0.3109 - accuracy: 0.8902 - val_loss: 0.3225 - val_accuracy: 0.8909
Epoch 21/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2912 - accuracy: 0.8930 - val_loss: 0.3211 - val_accuracy: 0.8905
Epoch 22/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2969 - accuracy: 0.8950 - val_loss: 0.3267 - val_accuracy: 0.8891
Epoch 23/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2958 - accuracy: 0.8944 - val_loss: 0.3319 - val_accuracy: 0.8884
Epoch 24/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2922 - accuracy: 0.8946 - val_loss: 0.3304 - val_accuracy: 0.8890
Epoch 25/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2852 - accuracy: 0.8984 - val_loss: 0.3208 - val_accuracy: 0.8902
Epoch 26/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2867 - accuracy: 0.8969 - val_loss: 0.3227 - val_accuracy: 0.8917
Epoch 27/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2831 - accuracy: 0.8993 - val_loss: 0.3291 - val_accuracy: 0.8893
Epoch 28/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2889 - accuracy: 0.8990 - val_loss: 0.3227 - val_accuracy: 0.8909
Epoch 29/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2907 - accuracy: 0.8970 - val_loss: 0.3287 - val_accuracy: 0.8913
Epoch 30/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2813 - accuracy: 0.9012 - val_loss: 0.3263 - val_accuracy: 0.8893
Epoch 31/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2835 - accuracy: 0.8977 - val_loss: 0.3193 - val_accuracy: 0.8953
Epoch 32/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2756 - accuracy: 0.9029 - val_loss: 0.3292 - val_accuracy: 0.8910
Epoch 33/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2770 - accuracy: 0.8997 - val_loss: 0.3308 - val_accuracy: 0.8936
Epoch 34/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2725 - accuracy: 0.9021 - val_loss: 0.3346 - val_accuracy: 0.8916
Epoch 35/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2873 - accuracy: 0.8992 - val_loss: 0.3345 - val_accuracy: 0.8910
Epoch 36/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2790 - accuracy: 0.9022 - val_loss: 0.3379 - val_accuracy: 0.8926
Epoch 37/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2790 - accuracy: 0.9024 - val_loss: 0.3375 - val_accuracy: 0.8931
Epoch 38/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2763 - accuracy: 0.9024 - val_loss: 0.3285 - val_accuracy: 0.8943
Epoch 39/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2750 - accuracy: 0.9041 - val_loss: 0.3266 - val_accuracy: 0.8946
Epoch 40/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2713 - accuracy: 0.9005 - val_loss: 0.3258 - val_accuracy: 0.8969
Epoch 41/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2789 - accuracy: 0.9019 - val_loss: 0.3314 - val_accuracy: 0.8953
Epoch 42/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2785 - accuracy: 0.9021 - val_loss: 0.3276 - val_accuracy: 0.8953
Epoch 43/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2718 - accuracy: 0.9039 - val_loss: 0.3352 - val_accuracy: 0.8906
Epoch 44/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2750 - accuracy: 0.9008 - val_loss: 0.3326 - val_accuracy: 0.8964
Epoch 45/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2791 - accuracy: 0.9011 - val_loss: 0.3297 - val_accuracy: 0.8940
Epoch 46/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2793 - accuracy: 0.9020 - val_loss: 0.3322 - val_accuracy: 0.8947
Epoch 47/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2718 - accuracy: 0.9031 - val_loss: 0.3422 - val_accuracy: 0.8911
Epoch 48/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2804 - accuracy: 0.9018 - val_loss: 0.3367 - val_accuracy: 0.8911
Epoch 49/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2670 - accuracy: 0.9039 - val_loss: 0.3391 - val_accuracy: 0.8927
Epoch 50/50
352/352 [==============================] - 1s 4ms/step - loss: 0.2743 - accuracy: 0.9034 - val_loss: 0.3409 - val_accuracy: 0.8899
313/313 [==============================] - 1s 2ms/step - loss: 0.3733 - accuracy: 0.8856
test_loss: 0.37328487634658813
test_acc: 0.8855999708175659
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[4]:</div>




<div class="output_png output_subarea output_execute_result">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fashion Mnist Results (Task 1)</p>
<table>
<thead><tr>
<th></th>
<th>Train Accuracy</th>
<th>Train Loss</th>
<th>Val Accuracy</th>
<th>Val Loss</th>
<th>Test Accuracy</th>
<th>Test Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>Original</td>
<td>0.9034</td>
<td>0.2743</td>
<td>0.8899</td>
<td>0.3409</td>
<td>0.8856</td>
<td>0.3733</td>
</tr>
</tbody>
</table>
<hr/>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The fitting process again shows the good result with small losses, validation accuracy less than training accuracy and test accuracy of 0.88.</p>
<p>The plot for train/test accuracy loss also shows acceptable fit.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Plot training accuracy values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model accuracy&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot training loss values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#A8D4E9&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#C6ECB2&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 1.2 Train a ConvNet from scratch<a rel="noopener" class="anchor-link" href="#Task-1.2-Train-a-ConvNet-from-scratch">&#182;</a></h3><p><em>(weight ~5%)</em></p>
<p>Build a ConvNet to replace the densely connected network in Task 1.1. Report the classification accuracy on the test set. Aim to achieve higher accuracy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Import libraries</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">pyplot</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="o">%</span><span class="k">tensorflow_version</span> 2.x
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>2.4.1
2.4.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Load data, Train/Test split</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">fashion_mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Normalization, reshaping, labels to cathegorical</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># max value in the image set:</span>
<span class="nb">max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>

<span class="c1"># normalize the data</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">/</span><span class="nb">max</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">/</span><span class="nb">max</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_images shape: &quot;</span><span class="p">,</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_images shape: &quot;</span><span class="p">,</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># convert to the shape suitable for ConvNet model</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_images shape: &quot;</span><span class="p">,</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_images shape: &quot;</span><span class="p">,</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># import</span>
<span class="kn">from</span> <span class="nn">keras.utils.np_utils</span> <span class="k">import</span> <span class="n">to_categorical</span> 

<span class="c1"># convert to cathegorical</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="c1"># convert to cathegorical</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>train_images shape:  (60000, 28, 28)
test_images shape:  (10000, 28, 28)
train_images shape:  (60000, 28, 28, 1)
test_images shape:  (10000, 28, 28, 1)
(60000, 10)
(10000, 10)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Train/Validation split</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Split the train and the validation set for the fitting</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="n">train_images</span><span class="p">,</span> <span class="n">val_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_images shape: &quot;</span><span class="p">,</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_images shape: &quot;</span><span class="p">,</span><span class="n">val_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_labels shape: &quot;</span><span class="p">,</span><span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_labels shape :&quot;</span><span class="p">,</span><span class="n">val_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>train_images shape:  (54000, 28, 28, 1)
val_images shape:  (6000, 28, 28, 1)
train_labels shape:  (54000, 10)
val_labels shape : (6000, 10)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Import layers</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">confusion_matrix</span>

<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">model_from_json</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">MaxPool2D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">BatchNormalization</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="k">import</span> <span class="n">RMSprop</span><span class="p">,</span><span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="k">import</span> <span class="n">image</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="k">import</span> <span class="n">ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">ModelCheckpoint</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Construct layers</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>
<p>The ConvNet model with 871,530 trainable parameters. The input shape is (None, 28, 28, 1).</p>
<p>It consists of 5 Batch Normalization layers,  3 Dense layers, 3 conv2d.</p>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;Same&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;Same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;Same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;Same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="c1"># Models summary</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 32)        320       
_________________________________________________________________
batch_normalization_1 (Batch (None, 28, 28, 32)        128       
_________________________________________________________________
activation (Activation)      (None, 28, 28, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      
_________________________________________________________________
batch_normalization_2 (Batch (None, 28, 28, 32)        128       
_________________________________________________________________
activation_1 (Activation)    (None, 28, 28, 32)        0         
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     
_________________________________________________________________
batch_normalization_3 (Batch (None, 14, 14, 64)        256       
_________________________________________________________________
activation_2 (Activation)    (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     
_________________________________________________________________
batch_normalization_4 (Batch (None, 14, 14, 64)        256       
_________________________________________________________________
activation_3 (Activation)    (None, 14, 14, 64)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 3136)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 256)               803072    
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024      
_________________________________________________________________
activation_4 (Activation)    (None, 256)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                2570      
=================================================================
Total params: 872,426
Trainable params: 871,530
Non-trainable params: 896
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Model Compilation</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>
<p>The optimizer is used Adam again (it showed better performance for fashion mnist in the previous experiments. TIt also helps to compare the quality of different models when they have the same parameter.</p>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Compile the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
              <span class="n">loss</span> <span class="o">=</span> <span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Fit the ConvNet model</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>
<p>For current experiemnt the verbose equals 2.</p>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># save the initial weights for later experiments</span>
<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="n">epochs</span><span class="o">=</span><span class="mi">50</span>
<span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                              <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                              <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span>
                              <span class="n">verbose</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
421/421 - 12s - loss: 0.3489 - accuracy: 0.8745 - val_loss: 0.4102 - val_accuracy: 0.8535
Epoch 2/50
421/421 - 4s - loss: 0.2205 - accuracy: 0.9186 - val_loss: 0.2345 - val_accuracy: 0.9160
Epoch 3/50
421/421 - 4s - loss: 0.1794 - accuracy: 0.9339 - val_loss: 0.2474 - val_accuracy: 0.9045
Epoch 4/50
421/421 - 4s - loss: 0.1476 - accuracy: 0.9459 - val_loss: 0.2133 - val_accuracy: 0.9267
Epoch 5/50
421/421 - 4s - loss: 0.1223 - accuracy: 0.9553 - val_loss: 0.2170 - val_accuracy: 0.9245
Epoch 6/50
421/421 - 4s - loss: 0.0979 - accuracy: 0.9634 - val_loss: 0.2144 - val_accuracy: 0.9270
Epoch 7/50
421/421 - 4s - loss: 0.0782 - accuracy: 0.9710 - val_loss: 0.2096 - val_accuracy: 0.9308
Epoch 8/50
421/421 - 4s - loss: 0.0654 - accuracy: 0.9766 - val_loss: 0.2181 - val_accuracy: 0.9347
Epoch 9/50
421/421 - 4s - loss: 0.0521 - accuracy: 0.9811 - val_loss: 0.2777 - val_accuracy: 0.9233
Epoch 10/50
421/421 - 4s - loss: 0.0457 - accuracy: 0.9833 - val_loss: 0.2514 - val_accuracy: 0.9307
Epoch 11/50
421/421 - 4s - loss: 0.0415 - accuracy: 0.9853 - val_loss: 0.2494 - val_accuracy: 0.9307
Epoch 12/50
421/421 - 4s - loss: 0.0335 - accuracy: 0.9888 - val_loss: 0.3354 - val_accuracy: 0.9130
Epoch 13/50
421/421 - 4s - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.2674 - val_accuracy: 0.9308
Epoch 14/50
421/421 - 4s - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.3317 - val_accuracy: 0.9235
Epoch 15/50
421/421 - 4s - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.3049 - val_accuracy: 0.9273
Epoch 16/50
421/421 - 4s - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.2805 - val_accuracy: 0.9305
Epoch 17/50
421/421 - 4s - loss: 0.0223 - accuracy: 0.9925 - val_loss: 0.3263 - val_accuracy: 0.9252
Epoch 18/50
421/421 - 4s - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.3093 - val_accuracy: 0.9312
Epoch 19/50
421/421 - 4s - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.3324 - val_accuracy: 0.9248
Epoch 20/50
421/421 - 4s - loss: 0.0195 - accuracy: 0.9934 - val_loss: 0.3768 - val_accuracy: 0.9263
Epoch 21/50
421/421 - 4s - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.4015 - val_accuracy: 0.9195
Epoch 22/50
421/421 - 4s - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.3232 - val_accuracy: 0.9297
Epoch 23/50
421/421 - 4s - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.4786 - val_accuracy: 0.9132
Epoch 24/50
421/421 - 4s - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.3298 - val_accuracy: 0.9323
Epoch 25/50
421/421 - 4s - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.3634 - val_accuracy: 0.9243
Epoch 26/50
421/421 - 4s - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.3213 - val_accuracy: 0.9338
Epoch 27/50
421/421 - 4s - loss: 0.0140 - accuracy: 0.9950 - val_loss: 0.3460 - val_accuracy: 0.9285
Epoch 28/50
421/421 - 4s - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.3766 - val_accuracy: 0.9268
Epoch 29/50
421/421 - 4s - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.3546 - val_accuracy: 0.9325
Epoch 30/50
421/421 - 4s - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.3773 - val_accuracy: 0.9290
Epoch 31/50
421/421 - 4s - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.3591 - val_accuracy: 0.9328
Epoch 32/50
421/421 - 4s - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.3782 - val_accuracy: 0.9265
Epoch 33/50
421/421 - 4s - loss: 0.0121 - accuracy: 0.9955 - val_loss: 0.3355 - val_accuracy: 0.9340
Epoch 34/50
421/421 - 4s - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.3573 - val_accuracy: 0.9302
Epoch 35/50
421/421 - 4s - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.3739 - val_accuracy: 0.9307
Epoch 36/50
421/421 - 4s - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.3674 - val_accuracy: 0.9305
Epoch 37/50
421/421 - 4s - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.3843 - val_accuracy: 0.9320
Epoch 38/50
421/421 - 4s - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.3512 - val_accuracy: 0.9348
Epoch 39/50
421/421 - 4s - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.3842 - val_accuracy: 0.9308
Epoch 40/50
421/421 - 4s - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.3977 - val_accuracy: 0.9288
Epoch 41/50
421/421 - 4s - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.3989 - val_accuracy: 0.9297
Epoch 42/50
421/421 - 4s - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.3871 - val_accuracy: 0.9305
Epoch 43/50
421/421 - 4s - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.4249 - val_accuracy: 0.9313
Epoch 44/50
421/421 - 4s - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.3864 - val_accuracy: 0.9312
Epoch 45/50
421/421 - 4s - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.4154 - val_accuracy: 0.9288
Epoch 46/50
421/421 - 4s - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.4116 - val_accuracy: 0.9315
Epoch 47/50
421/421 - 4s - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.4080 - val_accuracy: 0.9298
Epoch 48/50
421/421 - 4s - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.3484 - val_accuracy: 0.9353
Epoch 49/50
421/421 - 4s - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.3972 - val_accuracy: 0.9338
Epoch 50/50
421/421 - 4s - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.3910 - val_accuracy: 0.9338
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Test loss/accuracy</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;test_loss: </span><span class="si">{test_loss}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;test_acc: </span><span class="si">{test_acc}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>313/313 [==============================] - 1s 3ms/step - loss: 0.4503 - accuracy: 0.9278
test_loss: 0.45028695464134216
test_acc: 0.9277999997138977
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fashion Mnist Results (Task 1)</p>
<table>
<thead><tr>
<th></th>
<th>Train Accuracy</th>
<th>Train Loss</th>
<th>Val Accuracy</th>
<th>Val Loss</th>
<th>Test Accuracy</th>
<th>Test Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>Original</td>
<td>0.9034</td>
<td>0.2743</td>
<td>0.8899</td>
<td>0.3409</td>
<td>0.8856</td>
<td>0.3733</td>
</tr>
<tr>
<td>ConvNet</td>
<td>0.9980</td>
<td>0.0064</td>
<td>0.9338</td>
<td>0.3910</td>
<td>0.9277</td>
<td>0.4503</td>
</tr>
</tbody>
</table>
<hr/>
<p>The test accuracy shows significant improvement about 4.5% from the original model. Loss difference is insignificant.</p>
<p>The train accuracy of the ConvNet shows some overfitting that corresponds to validation/train accuracy plot. Validation precentage in the table also slightly high, but still lower than train accuracy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Plot for the loss and accuracy, for train and validation data</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Plot training accuracy values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model accuracy&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot training loss values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#A8D4E9&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#C6ECB2&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Validation accuracy shows moderate overfitting.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Orignal, predicted, probability, visual</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following code shows correctly identified class for randomly selected images from test set. In addition, it provides additional insights on the probability of other classes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">55</span><span class="p">):</span>
  <span class="n">original</span> <span class="o">=</span> <span class="n">test_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">test_images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">test_img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

  <span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">test_img</span><span class="p">)</span>
  <span class="n">prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_img</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original: &quot;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">original</span><span class="p">))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted: &quot;</span><span class="p">,</span><span class="n">predicted</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Probability: &quot;</span><span class="p">,</span><span class="n">prob</span><span class="p">)</span>

  <span class="c1">#Predict</span>
  <span class="c1">#print(test_images.shape)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span><span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Original:  4
Predicted:  [4]
Probability:  [[7.6436989e-16 5.1318567e-15 3.6924237e-13 2.1436586e-19 1.0000000e+00
  2.7269332e-15 1.6811940e-08 7.1772225e-16 6.5303752e-16 6.4235970e-14]]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Original:  4
Predicted:  [4]
Probability:  [[8.1655051e-11 1.5071464e-10 6.8905670e-04 3.2149108e-14 9.9887735e-01
  7.8104252e-09 4.3355228e-04 4.8865480e-13 1.3352143e-14 1.5435122e-09]]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Original:  5
Predicted:  [5]
Probability:  [[9.9167640e-17 4.1622167e-16 2.1278951e-25 1.2622379e-17 6.8050385e-23
  1.0000000e+00 1.2845336e-17 5.2559133e-14 2.5185208e-15 2.9338914e-20]]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Original:  8
Predicted:  [8]
Probability:  [[2.9705600e-12 1.0038892e-11 1.0465011e-11 3.6698417e-14 1.6817692e-18
  1.6786328e-13 3.5229277e-08 8.2638281e-17 1.0000000e+00 2.9027739e-10]]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Original:  2
Predicted:  [2]
Probability:  [[3.0367139e-13 2.0532528e-15 1.0000000e+00 4.1891865e-15 2.0700780e-12
  9.1420351e-15 3.3679777e-17 1.5672983e-13 1.8065446e-14 5.6488955e-16]]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Confusion Matrix</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_images</span><span class="p">)</span>
<span class="n">pred_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">original_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">original_label</span><span class="p">,</span> <span class="n">pred_label</span><span class="p">)</span> 

<span class="n">f</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s2">&quot;gnuplot&quot;</span><span class="p">,</span> <span class="n">linecolor</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.0f&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="c1">#ocean</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The color palette of confusion matrix very well shows a prevail number of successfully predicted labels.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet | <font color="#90AEE9">Number and percentage of correct predictions</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The percentage of correctly identified labels for every class. Classes 1, 5, 7 and 8 - this model suits the most. While class 6 shows the lowest predictability, with 180 out of 1000 images identified incorrectly.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Class:&quot;</span><span class="p">,</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of Wrong Prediction:&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">-</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">i</span><span class="p">]),</span> <span class="s2">&quot;out of 1000&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Percentage of True Prediction: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="mi">10</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;***********************************************************&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Class: 0
Number of Wrong Prediction: 109 out of 1000
Percentage of True Prediction: 89.10%
***********************************************************
Class: 1
Number of Wrong Prediction: 14 out of 1000
Percentage of True Prediction: 98.60%
***********************************************************
Class: 2
Number of Wrong Prediction: 90 out of 1000
Percentage of True Prediction: 91.00%
***********************************************************
Class: 3
Number of Wrong Prediction: 90 out of 1000
Percentage of True Prediction: 91.00%
***********************************************************
Class: 4
Number of Wrong Prediction: 108 out of 1000
Percentage of True Prediction: 89.20%
***********************************************************
Class: 5
Number of Wrong Prediction: 7 out of 1000
Percentage of True Prediction: 99.30%
***********************************************************
Class: 6
Number of Wrong Prediction: 232 out of 1000
Percentage of True Prediction: 76.80%
***********************************************************
Class: 7
Number of Wrong Prediction: 28 out of 1000
Percentage of True Prediction: 97.20%
***********************************************************
Class: 8
Number of Wrong Prediction: 16 out of 1000
Percentage of True Prediction: 98.40%
***********************************************************
Class: 9
Number of Wrong Prediction: 28 out of 1000
Percentage of True Prediction: 97.20%
***********************************************************
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 1.3 Build an input pipeline for data augmentation<a rel="noopener" class="anchor-link" href="#Task-1.3-Build-an-input-pipeline-for-data-augmentation">&#182;</a></h3><p><em>(weight ~3%)</em></p>
<p>Build a data preprocessing pipeline to perform data augmentation. (You may use Keras ImageDataGenerator or write your own transformations.)</p>
<ul>
<li><p>Report the new classification accuracy. Make sure that you use the same number of training epochs as in Task 1.2.</p>
</li>
<li><p>(Optional) Profile your input pipeline to identify the most time-consuming operation. What actions have you taken to address that slow operation? (<em>Hint: You may use the <a rel="noopener" href="https://github.com/tensorflow/profiler">TensorFlow Profiler</a>.</em>)</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet + Data Augmentation | <font color="#90AEE9">Keras ImageDataGenerator</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The most significant speed drop happens because google colab sometimes dissconect from GPU for the users that execute long computations.</p>
<p>The ImageDataGenerator execute rotation, zoom, width and hight changes. It allows to create additional data for training.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Data Augmentation</span>
<span class="n">datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span>
        <span class="n">rotation_range</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  
        <span class="n">zoom_range</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">width_shift_range</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> 
        <span class="n">height_shift_range</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> 

<span class="n">datagen</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet + Data Augmentation | <font color="#90AEE9">Fit the model</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># save the initial weights for later experiments</span>
<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="n">epochs</span><span class="o">=</span><span class="mi">50</span>
<span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">datagen</span><span class="o">.</span><span class="n">flow</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">),</span>
                              <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span>
                              <span class="n">verbose</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
421/421 - 14s - loss: 0.4579 - accuracy: 0.8642 - val_loss: 0.2371 - val_accuracy: 0.9162
Epoch 2/50
421/421 - 13s - loss: 0.2982 - accuracy: 0.8948 - val_loss: 0.2111 - val_accuracy: 0.9262
Epoch 3/50
421/421 - 13s - loss: 0.2649 - accuracy: 0.9049 - val_loss: 0.1881 - val_accuracy: 0.9323
Epoch 4/50
421/421 - 13s - loss: 0.2459 - accuracy: 0.9104 - val_loss: 0.2019 - val_accuracy: 0.9258
Epoch 5/50
421/421 - 13s - loss: 0.2339 - accuracy: 0.9153 - val_loss: 0.2096 - val_accuracy: 0.9213
Epoch 6/50
421/421 - 13s - loss: 0.2240 - accuracy: 0.9178 - val_loss: 0.2163 - val_accuracy: 0.9263
Epoch 7/50
421/421 - 13s - loss: 0.2162 - accuracy: 0.9214 - val_loss: 0.1849 - val_accuracy: 0.9307
Epoch 8/50
421/421 - 14s - loss: 0.2078 - accuracy: 0.9245 - val_loss: 0.2017 - val_accuracy: 0.9278
Epoch 9/50
421/421 - 13s - loss: 0.2044 - accuracy: 0.9242 - val_loss: 0.1991 - val_accuracy: 0.9263
Epoch 10/50
421/421 - 13s - loss: 0.1975 - accuracy: 0.9266 - val_loss: 0.2083 - val_accuracy: 0.9265
Epoch 11/50
421/421 - 13s - loss: 0.1939 - accuracy: 0.9284 - val_loss: 0.1929 - val_accuracy: 0.9345
Epoch 12/50
421/421 - 13s - loss: 0.1934 - accuracy: 0.9278 - val_loss: 0.1720 - val_accuracy: 0.9405
Epoch 13/50
421/421 - 13s - loss: 0.1858 - accuracy: 0.9311 - val_loss: 0.1667 - val_accuracy: 0.9398
Epoch 14/50
421/421 - 14s - loss: 0.1802 - accuracy: 0.9341 - val_loss: 0.1781 - val_accuracy: 0.9348
Epoch 15/50
421/421 - 14s - loss: 0.1815 - accuracy: 0.9336 - val_loss: 0.1982 - val_accuracy: 0.9303
Epoch 16/50
421/421 - 14s - loss: 0.1749 - accuracy: 0.9352 - val_loss: 0.1967 - val_accuracy: 0.9320
Epoch 17/50
421/421 - 14s - loss: 0.1709 - accuracy: 0.9371 - val_loss: 0.1680 - val_accuracy: 0.9437
Epoch 18/50
421/421 - 13s - loss: 0.1715 - accuracy: 0.9377 - val_loss: 0.1799 - val_accuracy: 0.9372
Epoch 19/50
421/421 - 13s - loss: 0.1654 - accuracy: 0.9392 - val_loss: 0.2037 - val_accuracy: 0.9292
Epoch 20/50
421/421 - 13s - loss: 0.1656 - accuracy: 0.9390 - val_loss: 0.1830 - val_accuracy: 0.9335
Epoch 21/50
421/421 - 13s - loss: 0.1627 - accuracy: 0.9393 - val_loss: 0.1852 - val_accuracy: 0.9383
Epoch 22/50
421/421 - 13s - loss: 0.1588 - accuracy: 0.9422 - val_loss: 0.1702 - val_accuracy: 0.9388
Epoch 23/50
421/421 - 14s - loss: 0.1566 - accuracy: 0.9421 - val_loss: 0.1800 - val_accuracy: 0.9388
Epoch 24/50
421/421 - 14s - loss: 0.1531 - accuracy: 0.9435 - val_loss: 0.1833 - val_accuracy: 0.9342
Epoch 25/50
421/421 - 14s - loss: 0.1500 - accuracy: 0.9450 - val_loss: 0.1835 - val_accuracy: 0.9355
Epoch 26/50
421/421 - 13s - loss: 0.1490 - accuracy: 0.9443 - val_loss: 0.1926 - val_accuracy: 0.9337
Epoch 27/50
421/421 - 13s - loss: 0.1483 - accuracy: 0.9449 - val_loss: 0.1790 - val_accuracy: 0.9383
Epoch 28/50
421/421 - 13s - loss: 0.1478 - accuracy: 0.9446 - val_loss: 0.2046 - val_accuracy: 0.9307
Epoch 29/50
421/421 - 13s - loss: 0.1453 - accuracy: 0.9464 - val_loss: 0.1820 - val_accuracy: 0.9415
Epoch 30/50
421/421 - 13s - loss: 0.1402 - accuracy: 0.9475 - val_loss: 0.2163 - val_accuracy: 0.9298
Epoch 31/50
421/421 - 13s - loss: 0.1402 - accuracy: 0.9480 - val_loss: 0.1736 - val_accuracy: 0.9428
Epoch 32/50
421/421 - 13s - loss: 0.1396 - accuracy: 0.9491 - val_loss: 0.1684 - val_accuracy: 0.9405
Epoch 33/50
421/421 - 13s - loss: 0.1354 - accuracy: 0.9497 - val_loss: 0.2097 - val_accuracy: 0.9322
Epoch 34/50
421/421 - 13s - loss: 0.1403 - accuracy: 0.9484 - val_loss: 0.1789 - val_accuracy: 0.9427
Epoch 35/50
421/421 - 13s - loss: 0.1339 - accuracy: 0.9511 - val_loss: 0.1867 - val_accuracy: 0.9382
Epoch 36/50
421/421 - 13s - loss: 0.1332 - accuracy: 0.9505 - val_loss: 0.1755 - val_accuracy: 0.9430
Epoch 37/50
421/421 - 13s - loss: 0.1304 - accuracy: 0.9509 - val_loss: 0.1855 - val_accuracy: 0.9358
Epoch 38/50
421/421 - 13s - loss: 0.1279 - accuracy: 0.9529 - val_loss: 0.1980 - val_accuracy: 0.9375
Epoch 39/50
421/421 - 13s - loss: 0.1301 - accuracy: 0.9515 - val_loss: 0.1717 - val_accuracy: 0.9408
Epoch 40/50
421/421 - 13s - loss: 0.1271 - accuracy: 0.9530 - val_loss: 0.1860 - val_accuracy: 0.9353
Epoch 41/50
421/421 - 13s - loss: 0.1274 - accuracy: 0.9526 - val_loss: 0.1875 - val_accuracy: 0.9393
Epoch 42/50
421/421 - 13s - loss: 0.1216 - accuracy: 0.9550 - val_loss: 0.1960 - val_accuracy: 0.9373
Epoch 43/50
421/421 - 13s - loss: 0.1232 - accuracy: 0.9550 - val_loss: 0.1832 - val_accuracy: 0.9377
Epoch 44/50
421/421 - 13s - loss: 0.1187 - accuracy: 0.9554 - val_loss: 0.1851 - val_accuracy: 0.9403
Epoch 45/50
421/421 - 13s - loss: 0.1233 - accuracy: 0.9540 - val_loss: 0.1894 - val_accuracy: 0.9423
Epoch 46/50
421/421 - 14s - loss: 0.1164 - accuracy: 0.9570 - val_loss: 0.1940 - val_accuracy: 0.9385
Epoch 47/50
421/421 - 13s - loss: 0.1170 - accuracy: 0.9567 - val_loss: 0.1986 - val_accuracy: 0.9325
Epoch 48/50
421/421 - 13s - loss: 0.1169 - accuracy: 0.9573 - val_loss: 0.1828 - val_accuracy: 0.9432
Epoch 49/50
421/421 - 13s - loss: 0.1183 - accuracy: 0.9555 - val_loss: 0.1786 - val_accuracy: 0.9435
Epoch 50/50
421/421 - 13s - loss: 0.1120 - accuracy: 0.9578 - val_loss: 0.1828 - val_accuracy: 0.9408
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet + Data Augmentation | <font color="#90AEE9">Comparison of accuracy ans loss for train/validation/test data</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span><span class="n">test_labels</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Accuracy:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Loss:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test Accuracy: 0.9373999834060669
Test Loss: 0.20556186139583588
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fashion Mnist Results (Task 1)</p>
<table>
<thead><tr>
<th></th>
<th>Train Accuracy</th>
<th>Train Loss</th>
<th>Val Accuracy</th>
<th>Val Loss</th>
<th>Test Accuracy</th>
<th>Test Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>Original</td>
<td>0.9034</td>
<td>0.2743</td>
<td>0.8899</td>
<td>0.3409</td>
<td>0.8856</td>
<td>0.3733</td>
</tr>
<tr>
<td>ConvNet</td>
<td>0.9980</td>
<td>0.0064</td>
<td>0.9338</td>
<td>0.3910</td>
<td>0.9277</td>
<td>0.4503</td>
</tr>
<tr>
<td>ConvNet + Data Augmentation</td>
<td>0.9578</td>
<td>0.1120</td>
<td>0.9408</td>
<td>0.1828</td>
<td>0.9374</td>
<td>0.2056</td>
</tr>
</tbody>
</table>
<p>The ConvNet + Data Augmentation has some overfitting, but overall high train accuracy and higher test accuracy than ConvNet without Data Augmentation. Additional parameter into DataImageGenerator could even more increse train set and improve test accuracy slightly more.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet + Data Augmentation | <font color="#90AEE9">Plot for the loss and accuracy, for train and validation data</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Validation accuracy shows little overfitting, but it is more stable after around 30 epoches.</p>
<p>The noisy movements of validation loss could mean some unrepresentativeness in the validation set.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Plot training accuracy values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model accuracy&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot training loss values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#A8D4E9&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#C6ECB2&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet + Data Augmentation | <font color="#90AEE9">Orignal, predicted, probability, visual</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">55</span><span class="p">):</span>
  <span class="n">original</span> <span class="o">=</span> <span class="n">test_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">test_images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">test_img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

  <span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">test_img</span><span class="p">)</span>
  <span class="n">prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_img</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original: &quot;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">original</span><span class="p">))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted: &quot;</span><span class="p">,</span><span class="n">predicted</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Probability: &quot;</span><span class="p">,</span><span class="n">prob</span><span class="p">)</span>

  <span class="c1">#Predict</span>
  <span class="c1">#print(test_images.shape)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span><span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Original:  4
Predicted:  [4]
Probability:  [[4.7513629e-07 4.5304767e-12 2.1024391e-05 2.4389553e-13 9.8775369e-01
  1.5056413e-12 1.2224699e-02 1.7992854e-13 1.9813436e-10 1.4488616e-12]]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Original:  4
Predicted:  [4]
Probability:  [[1.2076400e-08 8.0366410e-13 1.5083005e-03 2.2856387e-12 9.6081704e-01
  1.2148524e-12 3.7674591e-02 9.2012640e-14 1.1034597e-12 1.3030837e-11]]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Original:  5
Predicted:  [5]
Probability:  [[1.8780863e-14 8.0863845e-18 7.7296964e-17 1.9154039e-16 5.3669155e-20
  1.0000000e+00 1.5243942e-14 1.9959399e-10 9.5624286e-10 5.4334412e-13]]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Original:  8
Predicted:  [8]
Probability:  [[4.0774296e-07 1.9513166e-13 1.8411312e-12 3.7482040e-10 7.7085080e-15
  1.9265180e-12 1.2503998e-04 7.5855824e-15 9.9987459e-01 2.8602876e-09]]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Original:  2
Predicted:  [2]
Probability:  [[4.0463007e-08 5.3563859e-13 9.9998188e-01 2.0370315e-11 1.5051290e-05
  5.0453419e-13 3.0091758e-06 8.8341662e-10 2.2205097e-10 1.1215914e-12]]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet + Data Augmentation | <font color="#90AEE9">Confusion Matrix</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_images</span><span class="p">)</span>
<span class="n">pred_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">original_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">original_label</span><span class="p">,</span> <span class="n">pred_label</span><span class="p">)</span> 

<span class="n">f</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s2">&quot;gnuplot&quot;</span><span class="p">,</span> <span class="n">linecolor</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.0f&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="c1">#ocean</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">ConvNet + Data Augmentation | <font color="#90AEE9">Number and percentage of correct predictions</font></font></strong></p><font color="#C3D2F2"><font color="#90AEE9">
<hr/>

</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
</font></font></div><font color="#C3D2F2"><font color="#90AEE9">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Class:&quot;</span><span class="p">,</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of Wrong Prediction:&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">-</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">i</span><span class="p">]),</span> <span class="s2">&quot;out of 1000&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Percentage of True Prediction: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="mi">10</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;***********************************************************&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Class: 0
Number of Wrong Prediction: 103 out of 1000
Percentage of True Prediction: 89.70%
***********************************************************
Class: 1
Number of Wrong Prediction: 11 out of 1000
Percentage of True Prediction: 98.90%
***********************************************************
Class: 2
Number of Wrong Prediction: 111 out of 1000
Percentage of True Prediction: 88.90%
***********************************************************
Class: 3
Number of Wrong Prediction: 85 out of 1000
Percentage of True Prediction: 91.50%
***********************************************************
Class: 4
Number of Wrong Prediction: 100 out of 1000
Percentage of True Prediction: 90.00%
***********************************************************
Class: 5
Number of Wrong Prediction: 6 out of 1000
Percentage of True Prediction: 99.40%
***********************************************************
Class: 6
Number of Wrong Prediction: 150 out of 1000
Percentage of True Prediction: 85.00%
***********************************************************
Class: 7
Number of Wrong Prediction: 16 out of 1000
Percentage of True Prediction: 98.40%
***********************************************************
Class: 8
Number of Wrong Prediction: 6 out of 1000
Percentage of True Prediction: 99.40%
***********************************************************
Class: 9
Number of Wrong Prediction: 38 out of 1000
Percentage of True Prediction: 96.20%
***********************************************************
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 1.4 Fashion-MNIST with transfer learning<a rel="noopener" class="anchor-link" href="#Task-1.4-Fashion-MNIST-with-transfer-learning">&#182;</a></h3><p><em>(weight ~3%)</em></p>
<p>Use a pretrained model as the convolutional base to improve the classification performance. (Hint: You may use models in Keras Applications or those in the TensorFlow Hub.)</p>
<ul>
<li>Try both with fine-tuning and without fine-tuning.</li>
<li>Report the model performance as before.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Import Libraries</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1"># linear algebra</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> <span class="c1"># data processing, CSV file I/O (e.g. pd.read_csv)</span>
<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1">#from keras.datasets import fashion_mnist</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="k">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="c1">#from keras.layers.advanced_activations import LeakyReLU</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="k">import</span> <span class="n">ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">keras.applications</span> <span class="k">import</span> <span class="n">VGG16</span><span class="p">;</span>
<span class="kn">from</span> <span class="nn">keras.applications</span> <span class="k">import</span> <span class="n">VGG19</span><span class="p">;</span>
<span class="kn">from</span> <span class="nn">keras.applications.vgg16</span> <span class="k">import</span> <span class="n">preprocess_input</span>
<span class="kn">import</span> <span class="nn">os</span>



<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">pyplot</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="o">%</span><span class="k">tensorflow_version</span> 2.x
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>2.4.1
2.4.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Load Data</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#Train test split:</span>
<span class="n">fashion_mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Split the train and the validation set for the fitting</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="n">train_images</span><span class="p">,</span> <span class="n">val_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0
255
(54000, 28, 28)
(10000, 28, 28)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_images shape: &quot;</span><span class="p">,</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_images shape: &quot;</span><span class="p">,</span><span class="n">val_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_images shape: &quot;</span><span class="p">,</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_labels shape: &quot;</span><span class="p">,</span><span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_labels shape: &quot;</span><span class="p">,</span><span class="n">val_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_labels shape: &quot;</span><span class="p">,</span><span class="n">test_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>train_images shape:  (54000, 28, 28)
val_images shape:  (6000, 28, 28)
test_images shape:  (10000, 28, 28)
train_labels shape:  (54000,)
val_labels shape:  (6000,)
test_labels shape:  (10000,)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Data Shape Transformation</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">54000</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>
<span class="n">val_images</span> <span class="o">=</span> <span class="n">val_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">6000</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>

<span class="c1"># Convert the training and test images into 3 channels</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">([</span><span class="n">train_images</span><span class="p">]</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>
<span class="n">val_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">([</span><span class="n">val_images</span><span class="p">]</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">([</span><span class="n">test_images</span><span class="p">]</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>

<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">54000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">val_images</span> <span class="o">=</span> <span class="n">val_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">6000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>

<span class="c1"># Resize the images 150*150 as required by VGG19</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="k">import</span> <span class="n">img_to_array</span><span class="p">,</span> <span class="n">array_to_img</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">array_to_img</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">)))</span> <span class="k">for</span> <span class="n">im</span> <span class="ow">in</span> <span class="n">train_images</span><span class="p">])</span>
<span class="n">val_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">array_to_img</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">)))</span> <span class="k">for</span> <span class="n">im</span> <span class="ow">in</span> <span class="n">val_images</span><span class="p">])</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">array_to_img</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">)))</span> <span class="k">for</span> <span class="n">im</span> <span class="ow">in</span> <span class="n">test_images</span><span class="p">])</span>

<span class="c1"># Data Shape:</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_images shape: &quot;</span><span class="p">,</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_images shape: &quot;</span><span class="p">,</span><span class="n">val_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_images shape: &quot;</span><span class="p">,</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>test_images shape:  (54000, 50, 50, 3)
train_images shape:  (6000, 50, 50, 3)
test_images shape:  (10000, 50, 50, 3)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Normalization, labels to cathegorical</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">max</span> <span class="o">=</span><span class="mi">255</span>
<span class="c1">#Normalization:</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>
<span class="n">val_images</span> <span class="o">=</span> <span class="n">val_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>

<span class="c1">#Labels to cathegorical</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="k">import</span> <span class="n">to_categorical</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">val_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">val_labels</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Preprocessing the input</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Preprocessing the input </span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">preprocess_input</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>
<span class="n">val_images</span> <span class="o">=</span> <span class="n">preprocess_input</span><span class="p">(</span><span class="n">val_images</span><span class="p">)</span>
<span class="n">test_images</span>  <span class="o">=</span> <span class="n">preprocess_input</span> <span class="p">(</span><span class="n">test_images</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Model base and summary</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.applications</span> <span class="k">import</span> <span class="n">VGG16</span>

<span class="n">conv_base</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span>
                  <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">conv_base</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &quot;vgg16&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 50, 50, 3)]       0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 50, 50, 64)        1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 50, 50, 64)        36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 25, 25, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 25, 25, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 25, 25, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> To freeze the model</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">conv_base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># to freeze the model</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Extracting features</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[34]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span>

<span class="c1"># Extracting features</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">conv_base</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_images</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">conv_base</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_images</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">val_features</span> <span class="o">=</span> <span class="n">conv_base</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_images</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>422/422 [==============================] - 17s 36ms/step
79/79 [==============================] - 3s 38ms/step
47/47 [==============================] - 2s 34ms/step
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Check Features Shape</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Current shape of features</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_features</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>  <span class="n">test_features</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">val_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(54000, 1, 1, 512) 
 (10000, 1, 1, 512) 
 (6000, 1, 1, 512)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> To freeze the model</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<p>---Flatten extracted features</p>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Flatten extracted features</span>
<span class="n">train_flat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="p">(</span><span class="mi">54000</span><span class="p">,</span> <span class="mi">1</span><span class="o">*</span><span class="mi">1</span><span class="o">*</span><span class="mi">512</span><span class="p">))</span>
<span class="n">test_flat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1</span><span class="o">*</span><span class="mi">1</span><span class="o">*</span><span class="mi">512</span><span class="p">))</span>
<span class="n">val_flat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">val_features</span><span class="p">,</span> <span class="p">(</span><span class="mi">6000</span><span class="p">,</span> <span class="mi">1</span><span class="o">*</span><span class="mi">1</span><span class="o">*</span><span class="mi">512</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Create The Model and Model Summary</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">models</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">optimizers</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">callbacks</span>
<span class="kn">from</span> <span class="nn">keras.layers.advanced_activations</span> <span class="k">import</span> <span class="n">LeakyReLU</span>

<span class="k">def</span> <span class="nf">make_model</span><span class="p">():</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">*</span><span class="mi">1</span><span class="o">*</span><span class="mi">512</span><span class="p">)))</span>
  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

  <span class="c1"># Compile the model.</span>
  <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
    <span class="c1"># optimizer=optimizers.RMSprop(lr=2e-5),</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &quot;sequential_2&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_4 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu (LeakyReLU)      (None, 512)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 10)                5130      
=================================================================
Total params: 267,786
Trainable params: 267,786
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Incorporating reduced learning and early stopping for callback</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span> 
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s1">&#39;best_model&#39;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span> <span class="n">factor</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">patience</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">min_lr</span> <span class="o">=</span> <span class="mf">0.00001</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">)</span>
 <span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Train the Model</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span> <span class="c1"># Train the the model</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_flat</span><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_flat</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
422/422 [==============================] - 2s 3ms/step - loss: 2.3347 - acc: 0.2460 - val_loss: 1.5566 - val_acc: 0.4165
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 2/50
422/422 [==============================] - 1s 3ms/step - loss: 1.4739 - acc: 0.4638 - val_loss: 1.3272 - val_acc: 0.4778
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 3/50
422/422 [==============================] - 1s 3ms/step - loss: 1.2829 - acc: 0.5231 - val_loss: 1.2456 - val_acc: 0.5527
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 4/50
422/422 [==============================] - 1s 3ms/step - loss: 1.1984 - acc: 0.5560 - val_loss: 1.1408 - val_acc: 0.5870
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 5/50
422/422 [==============================] - 1s 3ms/step - loss: 1.1382 - acc: 0.5787 - val_loss: 1.2074 - val_acc: 0.5470
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 6/50
422/422 [==============================] - 1s 3ms/step - loss: 1.1051 - acc: 0.5889 - val_loss: 1.1591 - val_acc: 0.5527
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 7/50
422/422 [==============================] - 1s 3ms/step - loss: 1.0757 - acc: 0.6012 - val_loss: 1.0586 - val_acc: 0.6172
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 8/50
422/422 [==============================] - 1s 3ms/step - loss: 1.0440 - acc: 0.6185 - val_loss: 1.0689 - val_acc: 0.5877
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 9/50
422/422 [==============================] - 1s 3ms/step - loss: 1.0252 - acc: 0.6247 - val_loss: 1.0007 - val_acc: 0.6397
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 10/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9915 - acc: 0.6392 - val_loss: 0.9930 - val_acc: 0.6328
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 11/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9760 - acc: 0.6433 - val_loss: 0.9477 - val_acc: 0.6580
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 12/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9578 - acc: 0.6534 - val_loss: 0.9381 - val_acc: 0.6602
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 13/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9406 - acc: 0.6616 - val_loss: 0.9485 - val_acc: 0.6680
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 14/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9332 - acc: 0.6594 - val_loss: 0.9667 - val_acc: 0.6475
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 15/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9198 - acc: 0.6692 - val_loss: 0.9045 - val_acc: 0.6727
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 16/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8970 - acc: 0.6768 - val_loss: 0.9569 - val_acc: 0.6258
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 17/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9127 - acc: 0.6698 - val_loss: 0.9017 - val_acc: 0.6763
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 18/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9034 - acc: 0.6713 - val_loss: 0.9142 - val_acc: 0.6398
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 19/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8850 - acc: 0.6812 - val_loss: 0.8939 - val_acc: 0.6633
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 20/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8766 - acc: 0.6836 - val_loss: 0.9103 - val_acc: 0.6490
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 21/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8763 - acc: 0.6823 - val_loss: 0.8672 - val_acc: 0.6767
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 22/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8558 - acc: 0.6906 - val_loss: 0.8665 - val_acc: 0.6817
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 23/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8732 - acc: 0.6841 - val_loss: 0.8970 - val_acc: 0.6590
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 24/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8526 - acc: 0.6922 - val_loss: 0.9033 - val_acc: 0.6643
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 25/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8524 - acc: 0.6916 - val_loss: 0.9283 - val_acc: 0.6427
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.

Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Epoch 26/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8072 - acc: 0.7130 - val_loss: 0.8181 - val_acc: 0.7060
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 27/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7988 - acc: 0.7206 - val_loss: 0.8229 - val_acc: 0.7025
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 28/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7928 - acc: 0.7230 - val_loss: 0.8175 - val_acc: 0.7042
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 29/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7915 - acc: 0.7194 - val_loss: 0.8176 - val_acc: 0.7012
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 30/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7940 - acc: 0.7204 - val_loss: 0.8114 - val_acc: 0.7053
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 31/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7911 - acc: 0.7230 - val_loss: 0.8219 - val_acc: 0.6957
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 32/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7908 - acc: 0.7213 - val_loss: 0.8111 - val_acc: 0.7050
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 33/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7960 - acc: 0.7189 - val_loss: 0.8187 - val_acc: 0.7007
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 34/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7891 - acc: 0.7199 - val_loss: 0.8091 - val_acc: 0.7068
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 35/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7862 - acc: 0.7219 - val_loss: 0.8070 - val_acc: 0.7058
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 36/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7862 - acc: 0.7231 - val_loss: 0.8076 - val_acc: 0.7037
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 37/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7912 - acc: 0.7205 - val_loss: 0.8107 - val_acc: 0.7047
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 38/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7917 - acc: 0.7221 - val_loss: 0.8036 - val_acc: 0.7077
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 39/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7819 - acc: 0.7255 - val_loss: 0.8091 - val_acc: 0.7052
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 40/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7827 - acc: 0.7257 - val_loss: 0.8065 - val_acc: 0.7067
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 41/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7846 - acc: 0.7218 - val_loss: 0.8032 - val_acc: 0.7037
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 42/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7723 - acc: 0.7270 - val_loss: 0.8101 - val_acc: 0.7072
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 43/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7810 - acc: 0.7271 - val_loss: 0.8034 - val_acc: 0.7088
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 44/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7803 - acc: 0.7249 - val_loss: 0.8153 - val_acc: 0.7020
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.

Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Epoch 45/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7766 - acc: 0.7260 - val_loss: 0.7951 - val_acc: 0.7082
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 46/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7757 - acc: 0.7281 - val_loss: 0.7961 - val_acc: 0.7103
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 47/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7626 - acc: 0.7345 - val_loss: 0.7951 - val_acc: 0.7090
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 48/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7703 - acc: 0.7298 - val_loss: 0.7950 - val_acc: 0.7097
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 49/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7707 - acc: 0.7298 - val_loss: 0.7948 - val_acc: 0.7097
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 50/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7712 - acc: 0.7302 - val_loss: 0.7964 - val_acc: 0.7100
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Test loss/accuracy</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">score</span> <span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_flat</span><span class="p">,</span><span class="n">test_labels</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Accuracy:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Loss:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test Accuracy: 0.720300018787384
Test Loss: 0.7969239354133606
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> Without Fine-Tuning | <font color="#6D8AC3"> Plot Train/Test Accuracy and Loss</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[41]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># plot the loss and accuracy</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Validation accuracy shows little overfitting.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fashion Mnist Results (Task 1)</p>
<table>
<thead><tr>
<th></th>
<th>Train Accuracy</th>
<th>Train Loss</th>
<th>Val Accuracy</th>
<th>Val Loss</th>
<th>Test Accuracy</th>
<th>Test Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>Original</td>
<td>0.9034</td>
<td>0.2743</td>
<td>0.8899</td>
<td>0.3409</td>
<td>0.8856</td>
<td>0.3733</td>
</tr>
<tr>
<td>ConvNet</td>
<td>0.9980</td>
<td>0.0064</td>
<td>0.9338</td>
<td>0.3910</td>
<td>0.9277</td>
<td>0.4503</td>
</tr>
<tr>
<td>ConvNet + Data Augmentation</td>
<td>0.9578</td>
<td>0.1120</td>
<td>0.9408</td>
<td>0.1828</td>
<td>0.9374</td>
<td>0.2056</td>
</tr>
<tr>
<td>Transfer Learning Without Fine-Tuning</td>
<td>0.7302</td>
<td>0.7712</td>
<td>0.7100</td>
<td>0.7964</td>
<td>0.7203</td>
<td>0.7969</td>
</tr>
</tbody>
</table>
<hr/>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">Transfer Learning | <font color="#90AEE9"> With Fine-Tuning</font></font></strong><font color="#C3D2F2"><font color="#90AEE9"> | <font color="#6D8AC3"> <strong>Set</strong></font></font></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[42]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># To unfreeze the model</span>
<span class="n">conv_base</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">set_trainable</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">conv_base</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;block5_conv1&#39;</span><span class="p">:</span>
        <span class="n">set_trainable</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="n">set_trainable</span><span class="p">:</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong><font color="#C3D2F2">Transfer Learning | <font color="#90AEE9"> With Fine-Tuning</font></font></strong><font color="#C3D2F2"><font color="#90AEE9"> | <font color="#6D8AC3"> <strong>Model</strong></font></font></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[43]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
    <span class="c1"># optimizer=optimizers.RMSprop(lr=2e-5),</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">])</span>


<span class="n">fine_tuned_history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_flat</span><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_flat</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
422/422 [==============================] - 2s 3ms/step - loss: 2.5130 - acc: 0.2250 - val_loss: 1.5772 - val_acc: 0.4680
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 2/50
422/422 [==============================] - 1s 3ms/step - loss: 1.4735 - acc: 0.4577 - val_loss: 1.3125 - val_acc: 0.4778
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 3/50
422/422 [==============================] - 1s 3ms/step - loss: 1.2910 - acc: 0.5139 - val_loss: 1.2643 - val_acc: 0.4870
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 4/50
422/422 [==============================] - 1s 3ms/step - loss: 1.1928 - acc: 0.5488 - val_loss: 1.1536 - val_acc: 0.5805
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 5/50
422/422 [==============================] - 1s 3ms/step - loss: 1.1230 - acc: 0.5916 - val_loss: 1.1410 - val_acc: 0.5897
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 6/50
422/422 [==============================] - 1s 3ms/step - loss: 1.0944 - acc: 0.5972 - val_loss: 1.0833 - val_acc: 0.5877
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 7/50
422/422 [==============================] - 1s 3ms/step - loss: 1.0533 - acc: 0.6110 - val_loss: 1.0331 - val_acc: 0.6017
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 8/50
422/422 [==============================] - 1s 3ms/step - loss: 1.0272 - acc: 0.6237 - val_loss: 1.0065 - val_acc: 0.6228
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 9/50
422/422 [==============================] - 1s 3ms/step - loss: 1.0055 - acc: 0.6310 - val_loss: 0.9867 - val_acc: 0.6348
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 10/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9913 - acc: 0.6351 - val_loss: 0.9720 - val_acc: 0.6510
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 11/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9768 - acc: 0.6441 - val_loss: 1.0001 - val_acc: 0.6052
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 12/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9503 - acc: 0.6499 - val_loss: 0.9457 - val_acc: 0.6510
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 13/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9440 - acc: 0.6544 - val_loss: 0.9796 - val_acc: 0.6392
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 14/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9232 - acc: 0.6627 - val_loss: 0.9478 - val_acc: 0.6568
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 15/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9155 - acc: 0.6675 - val_loss: 0.9453 - val_acc: 0.6593
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 16/50
422/422 [==============================] - 1s 3ms/step - loss: 0.9153 - acc: 0.6680 - val_loss: 0.9011 - val_acc: 0.6703
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 17/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8991 - acc: 0.6743 - val_loss: 0.8773 - val_acc: 0.6747
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 18/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8816 - acc: 0.6828 - val_loss: 0.9940 - val_acc: 0.6302
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 19/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8940 - acc: 0.6743 - val_loss: 0.9181 - val_acc: 0.6600
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 20/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8598 - acc: 0.6888 - val_loss: 0.8994 - val_acc: 0.6758
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Epoch 21/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8201 - acc: 0.7101 - val_loss: 0.8358 - val_acc: 0.6952
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 22/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8142 - acc: 0.7132 - val_loss: 0.8373 - val_acc: 0.7000
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 23/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8105 - acc: 0.7156 - val_loss: 0.8359 - val_acc: 0.6982
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 24/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8093 - acc: 0.7144 - val_loss: 0.8415 - val_acc: 0.6955
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.

Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Epoch 25/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8125 - acc: 0.7138 - val_loss: 0.8312 - val_acc: 0.7025
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 26/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8084 - acc: 0.7162 - val_loss: 0.8315 - val_acc: 0.7003
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 27/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8018 - acc: 0.7186 - val_loss: 0.8294 - val_acc: 0.7017
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 28/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8057 - acc: 0.7173 - val_loss: 0.8296 - val_acc: 0.7005
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 29/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8082 - acc: 0.7156 - val_loss: 0.8302 - val_acc: 0.7012
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 30/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8019 - acc: 0.7160 - val_loss: 0.8292 - val_acc: 0.7010
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 31/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8073 - acc: 0.7179 - val_loss: 0.8294 - val_acc: 0.7007
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 32/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8074 - acc: 0.7155 - val_loss: 0.8289 - val_acc: 0.7013
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 33/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8017 - acc: 0.7203 - val_loss: 0.8287 - val_acc: 0.7007
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 34/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8132 - acc: 0.7150 - val_loss: 0.8294 - val_acc: 0.7007
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 35/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8141 - acc: 0.7151 - val_loss: 0.8285 - val_acc: 0.7010
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 36/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8088 - acc: 0.7168 - val_loss: 0.8280 - val_acc: 0.7005
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 37/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8067 - acc: 0.7175 - val_loss: 0.8280 - val_acc: 0.7018
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 38/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8084 - acc: 0.7154 - val_loss: 0.8286 - val_acc: 0.7023
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 39/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8078 - acc: 0.7183 - val_loss: 0.8278 - val_acc: 0.7025
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 40/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8096 - acc: 0.7170 - val_loss: 0.8281 - val_acc: 0.7008
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 41/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8058 - acc: 0.7158 - val_loss: 0.8271 - val_acc: 0.7027
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 42/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8092 - acc: 0.7166 - val_loss: 0.8278 - val_acc: 0.7015
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 43/50
422/422 [==============================] - 1s 3ms/step - loss: 0.7977 - acc: 0.7213 - val_loss: 0.8277 - val_acc: 0.7020
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 44/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8005 - acc: 0.7199 - val_loss: 0.8267 - val_acc: 0.7020
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 45/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8039 - acc: 0.7194 - val_loss: 0.8280 - val_acc: 0.6997
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 46/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8035 - acc: 0.7194 - val_loss: 0.8271 - val_acc: 0.7015
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 47/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8017 - acc: 0.7194 - val_loss: 0.8276 - val_acc: 0.7002
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.

Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-05.
Epoch 48/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8013 - acc: 0.7223 - val_loss: 0.8276 - val_acc: 0.7000
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 49/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8021 - acc: 0.7191 - val_loss: 0.8268 - val_acc: 0.7013
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Epoch 50/50
422/422 [==============================] - 1s 3ms/step - loss: 0.8032 - acc: 0.7176 - val_loss: 0.8256 - val_acc: 0.7022
WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
Model: &quot;sequential_3&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_6 (Dense)              (None, 512)               262656    
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 10)                5130      
=================================================================
Total params: 267,786
Trainable params: 267,786
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> With Fine-Tuning | <font color="#6D8AC3"> Test Accuracy and Loss</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[44]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Test Accuracy/Loss</span>

<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_flat</span><span class="p">,</span><span class="n">test_labels</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Accuracy:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Loss:&quot;</span><span class="p">,</span><span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test Accuracy: 0.7074000239372253
Test Loss: 0.8288720846176147
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> With Fine-Tuning | <font color="#6D8AC3"> Plot Train/Test Accuracy and Loss</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[45]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># plot the loss and accuracy</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">fine_tuned_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">fine_tuned_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">fine_tuned_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">fine_tuned_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Validation accuracy shows little overfitting.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 1.5 Performance comparison<a rel="noopener" class="anchor-link" href="#Task-1.5-Performance-comparison">&#182;</a></h3><p><em>(weight ~3%)</em></p>
<p>How many parameters are trainable in each of the two settings (with and without fine-tuning)? How does the difference impact the training time?</p>
<p>Which setting achieved higher accuracy? Why did it work better for this problem?</p>
<p>Have we benefitted from using the pretrained model?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fashion Mnist Results (Task 1)</p>
<table>
<thead><tr>
<th></th>
<th>Train Accuracy</th>
<th>Train Loss</th>
<th>Val Accuracy</th>
<th>Val Loss</th>
<th>Test Accuracy</th>
<th>Test Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>Original</td>
<td>0.9034</td>
<td>0.2743</td>
<td>0.8899</td>
<td>0.3409</td>
<td>0.8856</td>
<td>0.3733</td>
</tr>
<tr>
<td>ConvNet</td>
<td>0.9980</td>
<td>0.0064</td>
<td>0.9338</td>
<td>0.3910</td>
<td>0.9277</td>
<td>0.4503</td>
</tr>
<tr>
<td>ConvNet + Data Augmentation</td>
<td>0.9578</td>
<td>0.1120</td>
<td>0.9408</td>
<td>0.1828</td>
<td>0.9374</td>
<td>0.2056</td>
</tr>
<tr>
<td>Transfer Learning Without Fine-Tuning</td>
<td>0.7302</td>
<td>0.7712</td>
<td>0.7100</td>
<td>0.7964</td>
<td>0.7203</td>
<td>0.7969</td>
</tr>
<tr>
<td>Transfer Learning With Fine-Tuning</td>
<td>0.7176</td>
<td>0.8032</td>
<td>0.7022</td>
<td>0.8256</td>
<td>0.7074</td>
<td>0.8289</td>
</tr>
</tbody>
</table>
<hr/>
<p>Transfer Learning shows more poor results than original model or ConvNet model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Transfer Learning | <font color="#90AEE9"> With Fine-Tuning | <font color="#6D8AC3"> Plot Train/Test Accuracy and Loss</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>
<p><strong>How many parameters are trainable in each of the two settings (with and without fine-tuning)? How does the difference impact the training time?</strong></p>
<p>There are 267,786 parameters in the model with fine tuning. For this example training time differs insignificantly.</p>
<p>Which setting achieved higher accuracy? Why did it work better for this problem?</p>
<p>The Transfer Learning with Fine-Tuning archived a slightly smaller test accuracy for this exmaple.</p>
<p><strong>Have we benefitted from using the pretrained model?</strong></p>
<p>It is useful because it could help to save time.
Also, when the data is too large and has similarities it could show good results.</p>
<p>Fine-tuned model shows very similar results for this example. Since the Fashion Mnist dataset is big and has a lot of similar data, then almost the same accuracy result on the model without Fine-Tuning is expected.</p>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 2 Fast training of deep networks<a rel="noopener" class="anchor-link" href="#Task-2-Fast-training-of-deep-networks">&#182;</a></h2><p><em>(weight ~20%)</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 2.1 Train a highly accurate network for CIFAR10<a rel="noopener" class="anchor-link" href="#Task-2.1-Train-a-highly-accurate-network-for-CIFAR10">&#182;</a></h3><p><em>(weight ~7%)</em></p>
<p>In this task, you will train deep neural networks on the <a rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10 dataset</a>. Compared with the datasets that you have worked on so far, CIFAR10 represents a relatively larger multi-class classification problem and presents a great opportunity for you to solve a &quot;harder&quot; problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4>Task 2.1.1 Document the hardware used<a rel="noopener" class="anchor-link" href="#Task-2.1.1-Document-the-hardware-used">&#182;</a></h4><p>Before you start, write down your hardware specifications, including</p>
<ul>
<li>the GPU model, the number of GPUs, and the GPU memory</li>
<li>the CPU model, the number of CPUs, and the CPU clock speed</li>
</ul>
<p>(Hint: you may find commands like <code>nvidia-smi</code>, <code>lscpu</code> or <code>psutil</code> useful.)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Check the number of GPUs, and the GPU memory</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[46]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>nvidia-smi
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Thu May 20 02:56:53 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   71C    P0    31W /  70W |   4928MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Check the number of GPUs, and the GPU memory</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[47]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>lscpu
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
CPU(s):              2
On-line CPU(s) list: 0,1
Thread(s) per core:  2
Core(s) per socket:  1
Socket(s):           1
NUMA node(s):        1
Vendor ID:           GenuineIntel
CPU family:          6
Model:               79
Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz
Stepping:            0
CPU MHz:             2199.998
BogoMIPS:            4399.99
Hypervisor vendor:   KVM
Virtualization type: full
L1d cache:           32K
L1i cache:           32K
L2 cache:            256K
L3 cache:            56320K
NUMA node0 CPU(s):   0,1
Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4>Task 2.1.2 Train a &quot;shallow&quot; ConvNet<a rel="noopener" class="anchor-link" href="#Task-2.1.2-Train-a-&quot;shallow&quot;-ConvNet">&#182;</a></h4><p>Build a ConvNet with fewer than 10 layers. Train the network until it converges. You will use this network as a baseline for the later experiments.</p>
<ul>
<li>Plot the training and validation history. </li>
<li>Report the testing accuracy. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Import libraries</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[48]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">pyplot</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="o">%</span><span class="k">tensorflow_version</span> 2.x
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>2.4.1
2.4.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[49]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="k">import</span> <span class="n">cifar10</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.losses</span> <span class="k">import</span> <span class="n">categorical_crossentropy</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="k">import</span> <span class="n">Adam</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Import Cifar10 dataset</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[50]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">cifar10</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span>

<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0
255
(50000, 32, 32, 3)
(10000, 32, 32, 3)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Plot 9 images</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[51]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#Plot of 25 images:</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
	<span class="c1"># Define subplot:</span>
	<span class="n">pyplot</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>
	<span class="c1"># Raw pixel data:</span>
	<span class="n">pyplot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_images</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="c1">#Show</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Transform Image</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[52]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Resize the images 150*150 as required by VGG19</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="k">import</span> <span class="n">img_to_array</span><span class="p">,</span> <span class="n">array_to_img</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">array_to_img</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)))</span> <span class="k">for</span> <span class="n">im</span> <span class="ow">in</span> <span class="n">train_images</span><span class="p">])</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">array_to_img</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)))</span> <span class="k">for</span> <span class="n">im</span> <span class="ow">in</span> <span class="n">test_images</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.0
255.0
(50000, 28, 28, 3)
(10000, 28, 28, 3)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Preprocessing</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[53]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Max value in the image set:</span>
<span class="nb">max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>

<span class="c1">#Normalization:</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>

<span class="c1">#Labels to cathegorical</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="k">import</span> <span class="n">to_categorical</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.0
1.0
(50000, 28, 28, 3)
(10000, 28, 28, 3)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Train/Validation Split</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[54]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Split the train and the validation set for the fitting</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="n">train_images</span><span class="p">,</span> <span class="n">val_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_images shape: &quot;</span><span class="p">,</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_images shape: &quot;</span><span class="p">,</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_images shape: &quot;</span><span class="p">,</span><span class="n">val_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_labels shape: &quot;</span><span class="p">,</span><span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_lables shape: &quot;</span><span class="p">,</span><span class="n">test_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_labels shape :&quot;</span><span class="p">,</span><span class="n">val_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>train_images shape:  (45000, 28, 28, 3)
test_images shape:  (10000, 28, 28, 3)
val_images shape:  (5000, 28, 28, 3)
train_labels shape:  (45000, 10)
test_lables shape:  (10000, 10)
val_labels shape : (5000, 10)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Build the Model</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>
<p>This model has 2 Conv2D layers, 2 Max Pooling Layers and 3 Dense layers. The input shape is (28, 28, 3)</p>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[55]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">model_from_json</span> <span class="c1"># Create the model</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>


<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &quot;sequential_4&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 26, 26, 32)        896       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1600)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 128)               204928    
_________________________________________________________________
dense_9 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_10 (Dense)             (None, 10)                650       
=================================================================
Total params: 233,226
Trainable params: 233,226
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Compile the Model and Fit the Data</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[56]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Compile the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">categorical_crossentropy</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>


<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span>
<span class="c1"># Fit data to model</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span>
            <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
351/351 [==============================] - 3s 6ms/step - loss: 1.8679 - accuracy: 0.3052 - val_loss: 1.3939 - val_accuracy: 0.4970
Epoch 2/50
351/351 [==============================] - 2s 5ms/step - loss: 1.3334 - accuracy: 0.5206 - val_loss: 1.2334 - val_accuracy: 0.5726
Epoch 3/50
351/351 [==============================] - 2s 5ms/step - loss: 1.1900 - accuracy: 0.5771 - val_loss: 1.1580 - val_accuracy: 0.5916
Epoch 4/50
351/351 [==============================] - 2s 6ms/step - loss: 1.0872 - accuracy: 0.6185 - val_loss: 1.1079 - val_accuracy: 0.6102
Epoch 5/50
351/351 [==============================] - 2s 5ms/step - loss: 1.0036 - accuracy: 0.6464 - val_loss: 1.0273 - val_accuracy: 0.6426
Epoch 6/50
351/351 [==============================] - 2s 5ms/step - loss: 0.9495 - accuracy: 0.6683 - val_loss: 1.0064 - val_accuracy: 0.6450
Epoch 7/50
351/351 [==============================] - 2s 6ms/step - loss: 0.8972 - accuracy: 0.6854 - val_loss: 0.9848 - val_accuracy: 0.6650
Epoch 8/50
351/351 [==============================] - 2s 6ms/step - loss: 0.8664 - accuracy: 0.6991 - val_loss: 0.9773 - val_accuracy: 0.6612
Epoch 9/50
351/351 [==============================] - 2s 6ms/step - loss: 0.8141 - accuracy: 0.7175 - val_loss: 0.9461 - val_accuracy: 0.6754
Epoch 10/50
351/351 [==============================] - 2s 6ms/step - loss: 0.7722 - accuracy: 0.7328 - val_loss: 0.9253 - val_accuracy: 0.6836
Epoch 11/50
351/351 [==============================] - 2s 6ms/step - loss: 0.7338 - accuracy: 0.7477 - val_loss: 0.9510 - val_accuracy: 0.6788
Epoch 12/50
351/351 [==============================] - 2s 6ms/step - loss: 0.7077 - accuracy: 0.7532 - val_loss: 0.9684 - val_accuracy: 0.6758
Epoch 13/50
351/351 [==============================] - 2s 6ms/step - loss: 0.6716 - accuracy: 0.7684 - val_loss: 0.9145 - val_accuracy: 0.6976
Epoch 14/50
351/351 [==============================] - 2s 6ms/step - loss: 0.6275 - accuracy: 0.7809 - val_loss: 0.9463 - val_accuracy: 0.6786
Epoch 15/50
351/351 [==============================] - 2s 6ms/step - loss: 0.6148 - accuracy: 0.7857 - val_loss: 0.9394 - val_accuracy: 0.6866
Epoch 16/50
351/351 [==============================] - 2s 6ms/step - loss: 0.5830 - accuracy: 0.7988 - val_loss: 0.9938 - val_accuracy: 0.6844
Epoch 17/50
351/351 [==============================] - 2s 6ms/step - loss: 0.5580 - accuracy: 0.8045 - val_loss: 0.9681 - val_accuracy: 0.6928
Epoch 18/50
351/351 [==============================] - 2s 6ms/step - loss: 0.5248 - accuracy: 0.8152 - val_loss: 1.0078 - val_accuracy: 0.6838
Epoch 19/50
351/351 [==============================] - 2s 6ms/step - loss: 0.4997 - accuracy: 0.8259 - val_loss: 0.9986 - val_accuracy: 0.6916
Epoch 20/50
351/351 [==============================] - 2s 6ms/step - loss: 0.4718 - accuracy: 0.8351 - val_loss: 1.0437 - val_accuracy: 0.6772
Epoch 21/50
351/351 [==============================] - 2s 6ms/step - loss: 0.4527 - accuracy: 0.8409 - val_loss: 1.0742 - val_accuracy: 0.6698
Epoch 22/50
351/351 [==============================] - 2s 6ms/step - loss: 0.4268 - accuracy: 0.8496 - val_loss: 1.1229 - val_accuracy: 0.6750
Epoch 23/50
351/351 [==============================] - 2s 6ms/step - loss: 0.4119 - accuracy: 0.8527 - val_loss: 1.1201 - val_accuracy: 0.6884
Epoch 24/50
351/351 [==============================] - 2s 6ms/step - loss: 0.3739 - accuracy: 0.8695 - val_loss: 1.1239 - val_accuracy: 0.6842
Epoch 25/50
351/351 [==============================] - 2s 6ms/step - loss: 0.3596 - accuracy: 0.8757 - val_loss: 1.1538 - val_accuracy: 0.6890
Epoch 26/50
351/351 [==============================] - 2s 6ms/step - loss: 0.3308 - accuracy: 0.8865 - val_loss: 1.2274 - val_accuracy: 0.6832
Epoch 27/50
351/351 [==============================] - 2s 6ms/step - loss: 0.3046 - accuracy: 0.8930 - val_loss: 1.2713 - val_accuracy: 0.6784
Epoch 28/50
351/351 [==============================] - 2s 6ms/step - loss: 0.2887 - accuracy: 0.9017 - val_loss: 1.2891 - val_accuracy: 0.6838
Epoch 29/50
351/351 [==============================] - 2s 6ms/step - loss: 0.2595 - accuracy: 0.9093 - val_loss: 1.3562 - val_accuracy: 0.6790
Epoch 30/50
351/351 [==============================] - 2s 6ms/step - loss: 0.2543 - accuracy: 0.9092 - val_loss: 1.4299 - val_accuracy: 0.6762
Epoch 31/50
351/351 [==============================] - 2s 6ms/step - loss: 0.2419 - accuracy: 0.9154 - val_loss: 1.4730 - val_accuracy: 0.6780
Epoch 32/50
351/351 [==============================] - 2s 6ms/step - loss: 0.2123 - accuracy: 0.9235 - val_loss: 1.5166 - val_accuracy: 0.6770
Epoch 33/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1897 - accuracy: 0.9354 - val_loss: 1.6337 - val_accuracy: 0.6724
Epoch 34/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1815 - accuracy: 0.9374 - val_loss: 1.6803 - val_accuracy: 0.6780
Epoch 35/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1682 - accuracy: 0.9421 - val_loss: 1.7132 - val_accuracy: 0.6726
Epoch 36/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1616 - accuracy: 0.9433 - val_loss: 1.7954 - val_accuracy: 0.6744
Epoch 37/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1547 - accuracy: 0.9450 - val_loss: 1.8250 - val_accuracy: 0.6672
Epoch 38/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1490 - accuracy: 0.9480 - val_loss: 1.9111 - val_accuracy: 0.6642
Epoch 39/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1368 - accuracy: 0.9519 - val_loss: 2.0566 - val_accuracy: 0.6756
Epoch 40/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1277 - accuracy: 0.9561 - val_loss: 2.1824 - val_accuracy: 0.6624
Epoch 41/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1343 - accuracy: 0.9519 - val_loss: 2.0835 - val_accuracy: 0.6690
Epoch 42/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1192 - accuracy: 0.9586 - val_loss: 2.1493 - val_accuracy: 0.6740
Epoch 43/50
351/351 [==============================] - 2s 6ms/step - loss: 0.0937 - accuracy: 0.9680 - val_loss: 2.2416 - val_accuracy: 0.6792
Epoch 44/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1026 - accuracy: 0.9642 - val_loss: 2.3537 - val_accuracy: 0.6746
Epoch 45/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1019 - accuracy: 0.9659 - val_loss: 2.3592 - val_accuracy: 0.6676
Epoch 46/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1157 - accuracy: 0.9585 - val_loss: 2.4557 - val_accuracy: 0.6720
Epoch 47/50
351/351 [==============================] - 2s 6ms/step - loss: 0.0957 - accuracy: 0.9666 - val_loss: 2.4695 - val_accuracy: 0.6752
Epoch 48/50
351/351 [==============================] - 2s 6ms/step - loss: 0.0789 - accuracy: 0.9723 - val_loss: 2.5531 - val_accuracy: 0.6656
Epoch 49/50
351/351 [==============================] - 2s 6ms/step - loss: 0.0755 - accuracy: 0.9751 - val_loss: 2.5444 - val_accuracy: 0.6652
Epoch 50/50
351/351 [==============================] - 2s 6ms/step - loss: 0.1096 - accuracy: 0.9617 - val_loss: 2.5732 - val_accuracy: 0.6772
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Part 2. Cifar-10</strong></p>
<p>As expected, the Shallow &#39;CovNet&#39; shows low test accuracy overfitting in the train/validation accuracy plot.</p>
<table>
<thead><tr>
<th></th>
<th>Train Accuracy</th>
<th>Train Loss</th>
<th>Val Accuracy</th>
<th>Val Loss</th>
<th>Test Accuracy</th>
<th>Test Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fast Training, &quot;Shallow&quot; CovNet</td>
<td>0.9723</td>
<td>0.0789</td>
<td>0.6656</td>
<td>2.5531</td>
<td>0.6713</td>
<td>2.6417</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Test Loss and Test Accuracy</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[57]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Test Accuracy/Loss</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test loss: </span><span class="si">{score[0]}</span><span class="s1"> / Test accuracy: </span><span class="si">{score[1]}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 2.6416516304016113 / Test accuracy: 0.6712999939918518
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> &quot;Shallow&quot; CovNet | <font color="#6D8AC3"> Plot train/validation loss and accuracy</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[58]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># plot the loss and accuracy</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The validation accuracy shows strong overfitting.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4>Task 2.1.3 Train a ResNet<a rel="noopener" class="anchor-link" href="#Task-2.1.3-Train-a-ResNet">&#182;</a></h4><p>Train a residual neural network (ResNet) on the CIFAR10 training data and report the test accuracy and the training time.</p>
<p>The ResNet is a popular network architecture for image classification. You may find more information about how ResNet works by reading this <a rel="noopener" href="https://arxiv.org/abs/1512.03385">paper</a>.</p>
<p><em>(You may implement a resnet model or use an existing implementation. In either case, you should not use pretrained network weights.)</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet | <font color="#6D8AC3"> Import Libraries</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[59]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">pyplot</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="o">%</span><span class="k">tensorflow_version</span> 2.x
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>2.4.1
2.4.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet | <font color="#6D8AC3"> Import Dataset</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">cifar10</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span>

<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0
255
(50000, 32, 32, 3)
(10000, 32, 32, 3)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet | <font color="#6D8AC3"> Preproccesing</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Max value in the image set:</span>
<span class="nb">max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>

<span class="c1">#Normalization:</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>

<span class="c1">#Labels to cathegorical</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="k">import</span> <span class="n">to_categorical</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet | <font color="#6D8AC3"> Train/Validation Split</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Split the train and the validation set for the fitting</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="n">train_images</span><span class="p">,</span> <span class="n">val_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_images shape: &quot;</span><span class="p">,</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_images shape: &quot;</span><span class="p">,</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_images shape: &quot;</span><span class="p">,</span><span class="n">val_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_labels shape: &quot;</span><span class="p">,</span><span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_lables shape: &quot;</span><span class="p">,</span><span class="n">test_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_labels shape :&quot;</span><span class="p">,</span><span class="n">val_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>train_images shape:  (45000, 32, 32, 3)
test_images shape:  (10000, 32, 32, 3)
val_images shape:  (5000, 32, 32, 3)
train_labels shape:  (45000, 10)
test_lables shape:  (10000, 10)
val_labels shape : (5000, 10)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet | <font color="#6D8AC3"> Custom ResidualUnit layer and Create Model and Summar</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">partial</span>

<span class="n">DefaultConv2D</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">,</span> 
                        <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
                        <span class="p">)</span>

<span class="n">DefaultSeparableConv2D</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">SeparableConv2D</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                 <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">,</span> 
                                 <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                 <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">DepthwiseResidualUnit</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">main_layers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">DefaultSeparableConv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">),</span>
            <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">DefaultSeparableConv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">),</span>
            <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">skip_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">strides</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">skip_layers</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">DefaultConv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">),</span>
                <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_layers</span><span class="p">:</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
        <span class="n">skip_Z</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">skip_layers</span><span class="p">:</span>
            <span class="n">skip_Z</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">skip_Z</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">Z</span> <span class="o">+</span> <span class="n">skip_Z</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="n">prev_filters</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">prev_filters</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">prev_filters</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">prev_filters</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">prev_filters</span><span class="p">]</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">DefaultConv2D</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                        <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">DepthwiseResidualUnit</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">DepthwiseResidualUnit</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">DepthwiseResidualUnit</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">DepthwiseResidualUnit</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 32, 32, 64)        1728      
_________________________________________________________________
depthwise_residual_unit (Dep (None, 32, 32, 64)        9856      
_________________________________________________________________
depthwise_residual_unit_1 (D (None, 16, 16, 128)       36032     
_________________________________________________________________
depthwise_residual_unit_2 (D (None, 8, 8, 256)         137600    
_________________________________________________________________
depthwise_residual_unit_3 (D (None, 4, 4, 256)         204288    
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 10)                2570      
=================================================================
Total params: 392,074
Trainable params: 387,978
Non-trainable params: 4,096
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet | <font color="#6D8AC3"> Compile and Fit the model</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#%%time</span>


<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>


<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
352/352 [==============================] - 18s 44ms/step - loss: 5.5513 - accuracy: 0.3663 - val_loss: 3.4680 - val_accuracy: 0.1048
Epoch 2/50
352/352 [==============================] - 15s 42ms/step - loss: 1.8800 - accuracy: 0.5917 - val_loss: 1.9868 - val_accuracy: 0.4406
Epoch 3/50
352/352 [==============================] - 15s 42ms/step - loss: 1.1607 - accuracy: 0.6953 - val_loss: 1.3412 - val_accuracy: 0.6070
Epoch 4/50
352/352 [==============================] - 15s 42ms/step - loss: 0.9132 - accuracy: 0.7514 - val_loss: 1.0961 - val_accuracy: 0.6820
Epoch 5/50
352/352 [==============================] - 15s 41ms/step - loss: 0.7761 - accuracy: 0.7878 - val_loss: 1.2369 - val_accuracy: 0.6562
Epoch 6/50
352/352 [==============================] - 15s 42ms/step - loss: 0.6709 - accuracy: 0.8188 - val_loss: 0.9611 - val_accuracy: 0.7104
Epoch 7/50
352/352 [==============================] - 15s 42ms/step - loss: 0.5857 - accuracy: 0.8452 - val_loss: 1.0758 - val_accuracy: 0.6924
Epoch 8/50
352/352 [==============================] - 15s 42ms/step - loss: 0.5067 - accuracy: 0.8692 - val_loss: 0.8748 - val_accuracy: 0.7490
Epoch 9/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4308 - accuracy: 0.8930 - val_loss: 0.8468 - val_accuracy: 0.7554
Epoch 10/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3872 - accuracy: 0.9045 - val_loss: 1.2457 - val_accuracy: 0.6762
Epoch 11/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3386 - accuracy: 0.9213 - val_loss: 0.9501 - val_accuracy: 0.7464
Epoch 12/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2913 - accuracy: 0.9347 - val_loss: 0.9912 - val_accuracy: 0.7412
Epoch 13/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2560 - accuracy: 0.9459 - val_loss: 0.8001 - val_accuracy: 0.7850
Epoch 14/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2156 - accuracy: 0.9578 - val_loss: 0.9333 - val_accuracy: 0.7476
Epoch 15/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1969 - accuracy: 0.9621 - val_loss: 0.9112 - val_accuracy: 0.7602
Epoch 16/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1883 - accuracy: 0.9639 - val_loss: 1.0175 - val_accuracy: 0.7434
Epoch 17/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1782 - accuracy: 0.9670 - val_loss: 1.0028 - val_accuracy: 0.7544
Epoch 18/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1677 - accuracy: 0.9682 - val_loss: 0.9854 - val_accuracy: 0.7600
Epoch 19/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1496 - accuracy: 0.9734 - val_loss: 1.1033 - val_accuracy: 0.7468
Epoch 20/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1483 - accuracy: 0.9740 - val_loss: 1.1802 - val_accuracy: 0.7424
Epoch 21/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1316 - accuracy: 0.9790 - val_loss: 1.1098 - val_accuracy: 0.7530
Epoch 22/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1476 - accuracy: 0.9733 - val_loss: 1.1620 - val_accuracy: 0.7488
Epoch 23/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1446 - accuracy: 0.9746 - val_loss: 0.9683 - val_accuracy: 0.7772
Epoch 24/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1236 - accuracy: 0.9803 - val_loss: 0.9891 - val_accuracy: 0.7818
Epoch 25/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1295 - accuracy: 0.9780 - val_loss: 1.1548 - val_accuracy: 0.7500
Epoch 26/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1428 - accuracy: 0.9742 - val_loss: 1.1458 - val_accuracy: 0.7576
Epoch 27/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1130 - accuracy: 0.9828 - val_loss: 1.1150 - val_accuracy: 0.7678
Epoch 28/50
352/352 [==============================] - 15s 41ms/step - loss: 0.1154 - accuracy: 0.9813 - val_loss: 1.1548 - val_accuracy: 0.7578
Epoch 29/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1205 - accuracy: 0.9791 - val_loss: 1.1725 - val_accuracy: 0.7584
Epoch 30/50
352/352 [==============================] - 15s 41ms/step - loss: 0.1299 - accuracy: 0.9756 - val_loss: 1.1241 - val_accuracy: 0.7692
Epoch 31/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1051 - accuracy: 0.9846 - val_loss: 1.2641 - val_accuracy: 0.7630
Epoch 32/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0980 - accuracy: 0.9857 - val_loss: 1.4618 - val_accuracy: 0.7262
Epoch 33/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1159 - accuracy: 0.9796 - val_loss: 1.3064 - val_accuracy: 0.7446
Epoch 34/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1051 - accuracy: 0.9827 - val_loss: 1.3243 - val_accuracy: 0.7516
Epoch 35/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1178 - accuracy: 0.9801 - val_loss: 1.5113 - val_accuracy: 0.7092
Epoch 36/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1024 - accuracy: 0.9839 - val_loss: 1.1111 - val_accuracy: 0.7790
Epoch 37/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0852 - accuracy: 0.9877 - val_loss: 1.1599 - val_accuracy: 0.7752
Epoch 38/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0946 - accuracy: 0.9842 - val_loss: 1.1092 - val_accuracy: 0.7818
Epoch 39/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0972 - accuracy: 0.9843 - val_loss: 1.2475 - val_accuracy: 0.7592
Epoch 40/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1012 - accuracy: 0.9825 - val_loss: 1.1558 - val_accuracy: 0.7834
Epoch 41/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0917 - accuracy: 0.9846 - val_loss: 1.2733 - val_accuracy: 0.7726
Epoch 42/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0813 - accuracy: 0.9883 - val_loss: 1.1006 - val_accuracy: 0.7960
Epoch 43/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0812 - accuracy: 0.9884 - val_loss: 1.4103 - val_accuracy: 0.7640
Epoch 44/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0880 - accuracy: 0.9865 - val_loss: 1.1644 - val_accuracy: 0.7798
Epoch 45/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0685 - accuracy: 0.9901 - val_loss: 1.2016 - val_accuracy: 0.7788
Epoch 46/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0850 - accuracy: 0.9856 - val_loss: 1.1286 - val_accuracy: 0.7936
Epoch 47/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0773 - accuracy: 0.9875 - val_loss: 1.1506 - val_accuracy: 0.7848
Epoch 48/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0710 - accuracy: 0.9885 - val_loss: 1.2657 - val_accuracy: 0.7778
Epoch 49/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0788 - accuracy: 0.9871 - val_loss: 1.2610 - val_accuracy: 0.7774
Epoch 50/50
352/352 [==============================] - 15s 41ms/step - loss: 0.0708 - accuracy: 0.9890 - val_loss: 1.1889 - val_accuracy: 0.7800
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Part 2. Cifar-10</strong></p>
<p>The &#39;ResNet&#39; has better test accuracy smaller test loss and less overffiting on the train/val accuracy plot.</p>
<table>
<thead><tr>
<th></th>
<th>Train Accuracy</th>
<th>Train Loss</th>
<th>Val Accuracy</th>
<th>Val Loss</th>
<th>Test Accuracy</th>
<th>Test Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fast Training, &quot;Shallow&quot; CovNet</td>
<td>0.9723</td>
<td>0.0789</td>
<td>0.6656</td>
<td>2.5531</td>
<td>0.6713</td>
<td>2.6417</td>
<td>2 </td>
</tr>
<tr>
<td>Fast Training of ResNet</td>
<td>0.9890</td>
<td>0.0708</td>
<td>0.7800</td>
<td>1.1889</td>
<td>0.7792</td>
<td>1.1887</td>
<td>15</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet | <font color="#6D8AC3"> Test Loss and Test Accuracy</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Test Accuracy/Loss</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test loss: </span><span class="si">{score[0]}</span><span class="s1"> / Test accuracy: </span><span class="si">{score[1]}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 1.1887378692626953 / Test accuracy: 0.77920001745224
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet | <font color="#6D8AC3"> Plot train/validation loss and accuracy</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># plot the loss and accuracy</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The loss plot might show that the model is trained for too long</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>nvidia-smi
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Thu May 20 03:11:05 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   76C    P0    44W /  70W |   4928MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet (prepared model ResNet50) | <font color="#6D8AC3"> Create ResNet50 Model</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.applications.resnet50</span> <span class="k">import</span> <span class="n">ResNet50</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">(</span><span class="n">classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &quot;resnet50&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_2[0][0]                    
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           
__________________________________________________________________________________________________
predictions (Dense)             (None, 10)           20490       avg_pool[0][0]                   
==================================================================================================
Total params: 23,608,202
Trainable params: 23,555,082
Non-trainable params: 53,120
__________________________________________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet (prepared model ResNet50) | <font color="#6D8AC3"> Compile and Fit the model</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#%%time</span>

<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>


<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
352/352 [==============================] - 35s 79ms/step - loss: 2.2629 - accuracy: 0.2945 - val_loss: 10904.2842 - val_accuracy: 0.1010
Epoch 2/50
352/352 [==============================] - 25s 72ms/step - loss: 1.7530 - accuracy: 0.3943 - val_loss: 3.1015 - val_accuracy: 0.2094
Epoch 3/50
352/352 [==============================] - 25s 71ms/step - loss: 1.9736 - accuracy: 0.3738 - val_loss: 7.6342 - val_accuracy: 0.2644
Epoch 4/50
352/352 [==============================] - 25s 71ms/step - loss: 1.7616 - accuracy: 0.3966 - val_loss: 19.3433 - val_accuracy: 0.2522
Epoch 5/50
352/352 [==============================] - 25s 71ms/step - loss: 1.7758 - accuracy: 0.4081 - val_loss: 4.7143 - val_accuracy: 0.2936
Epoch 6/50
352/352 [==============================] - 25s 71ms/step - loss: 1.6267 - accuracy: 0.4412 - val_loss: 1.6591 - val_accuracy: 0.4074
Epoch 7/50
352/352 [==============================] - 25s 72ms/step - loss: 1.5315 - accuracy: 0.4840 - val_loss: 50.5493 - val_accuracy: 0.0858
Epoch 8/50
352/352 [==============================] - 25s 72ms/step - loss: 1.6081 - accuracy: 0.4414 - val_loss: 2.0088 - val_accuracy: 0.3124
Epoch 9/50
352/352 [==============================] - 25s 71ms/step - loss: 1.5551 - accuracy: 0.4829 - val_loss: 5.2304 - val_accuracy: 0.3394
Epoch 10/50
352/352 [==============================] - 25s 72ms/step - loss: 1.4675 - accuracy: 0.4880 - val_loss: 1.5641 - val_accuracy: 0.4498
Epoch 11/50
352/352 [==============================] - 25s 72ms/step - loss: 1.5047 - accuracy: 0.4967 - val_loss: 28.3975 - val_accuracy: 0.3188
Epoch 12/50
352/352 [==============================] - 25s 72ms/step - loss: 1.4941 - accuracy: 0.4926 - val_loss: 1.7482 - val_accuracy: 0.3866
Epoch 13/50
352/352 [==============================] - 25s 72ms/step - loss: 1.4599 - accuracy: 0.5261 - val_loss: 1.8285 - val_accuracy: 0.3566
Epoch 14/50
352/352 [==============================] - 25s 72ms/step - loss: 1.5861 - accuracy: 0.4718 - val_loss: 2.1042 - val_accuracy: 0.2566
Epoch 15/50
352/352 [==============================] - 25s 72ms/step - loss: 1.6479 - accuracy: 0.4286 - val_loss: 1.6399 - val_accuracy: 0.4482
Epoch 16/50
352/352 [==============================] - 25s 72ms/step - loss: 1.4000 - accuracy: 0.5230 - val_loss: 2.3970 - val_accuracy: 0.2758
Epoch 17/50
352/352 [==============================] - 25s 72ms/step - loss: 1.4231 - accuracy: 0.5206 - val_loss: 1.4567 - val_accuracy: 0.5086
Epoch 18/50
352/352 [==============================] - 25s 72ms/step - loss: 1.3239 - accuracy: 0.5531 - val_loss: 3.5410 - val_accuracy: 0.4722
Epoch 19/50
352/352 [==============================] - 25s 72ms/step - loss: 1.3034 - accuracy: 0.5647 - val_loss: 1.3778 - val_accuracy: 0.5002
Epoch 20/50
352/352 [==============================] - 25s 72ms/step - loss: 1.3659 - accuracy: 0.5533 - val_loss: 2.1382 - val_accuracy: 0.3120
Epoch 21/50
352/352 [==============================] - 25s 71ms/step - loss: 1.3248 - accuracy: 0.5491 - val_loss: 1.4534 - val_accuracy: 0.4888
Epoch 22/50
352/352 [==============================] - 25s 71ms/step - loss: 1.1657 - accuracy: 0.6060 - val_loss: 1.8183 - val_accuracy: 0.3990
Epoch 23/50
352/352 [==============================] - 25s 72ms/step - loss: 1.3175 - accuracy: 0.5624 - val_loss: 22.0294 - val_accuracy: 0.1340
Epoch 24/50
352/352 [==============================] - 25s 72ms/step - loss: 1.5681 - accuracy: 0.4795 - val_loss: 2.1883 - val_accuracy: 0.5018
Epoch 25/50
352/352 [==============================] - 25s 72ms/step - loss: 1.2311 - accuracy: 0.5768 - val_loss: 1.2963 - val_accuracy: 0.5618
Epoch 26/50
352/352 [==============================] - 25s 71ms/step - loss: 1.1704 - accuracy: 0.5925 - val_loss: 1.5155 - val_accuracy: 0.4822
Epoch 27/50
352/352 [==============================] - 25s 72ms/step - loss: 1.2496 - accuracy: 0.5679 - val_loss: 1.6690 - val_accuracy: 0.5352
Epoch 28/50
352/352 [==============================] - 25s 72ms/step - loss: 1.2205 - accuracy: 0.5881 - val_loss: 2.9442 - val_accuracy: 0.3994
Epoch 29/50
352/352 [==============================] - 25s 72ms/step - loss: 1.1414 - accuracy: 0.6192 - val_loss: 3.2519 - val_accuracy: 0.5594
Epoch 30/50
352/352 [==============================] - 25s 72ms/step - loss: 1.0911 - accuracy: 0.6394 - val_loss: 1.2594 - val_accuracy: 0.6218
Epoch 31/50
352/352 [==============================] - 25s 71ms/step - loss: 0.9883 - accuracy: 0.6687 - val_loss: 1.1798 - val_accuracy: 0.6034
Epoch 32/50
352/352 [==============================] - 25s 71ms/step - loss: 0.9418 - accuracy: 0.6770 - val_loss: 1.0556 - val_accuracy: 0.6300
Epoch 33/50
352/352 [==============================] - 25s 72ms/step - loss: 0.9424 - accuracy: 0.6871 - val_loss: 2.9733 - val_accuracy: 0.5804
Epoch 34/50
352/352 [==============================] - 25s 72ms/step - loss: 0.8465 - accuracy: 0.7225 - val_loss: 1.3867 - val_accuracy: 0.6436
Epoch 35/50
352/352 [==============================] - 25s 71ms/step - loss: 0.7350 - accuracy: 0.7515 - val_loss: 1.8753 - val_accuracy: 0.6574
Epoch 36/50
352/352 [==============================] - 25s 72ms/step - loss: 0.6968 - accuracy: 0.7718 - val_loss: 1.4448 - val_accuracy: 0.6588
Epoch 37/50
352/352 [==============================] - 25s 71ms/step - loss: 0.6450 - accuracy: 0.7874 - val_loss: 1.5098 - val_accuracy: 0.6130
Epoch 38/50
352/352 [==============================] - 25s 72ms/step - loss: 0.5611 - accuracy: 0.8081 - val_loss: 1.3038 - val_accuracy: 0.6556
Epoch 39/50
352/352 [==============================] - 26s 72ms/step - loss: 0.5138 - accuracy: 0.8326 - val_loss: 1.1779 - val_accuracy: 0.6726
Epoch 40/50
352/352 [==============================] - 25s 72ms/step - loss: 0.4464 - accuracy: 0.8531 - val_loss: 1.6445 - val_accuracy: 0.6606
Epoch 41/50
352/352 [==============================] - 25s 72ms/step - loss: 0.4134 - accuracy: 0.8681 - val_loss: 1.1455 - val_accuracy: 0.6502
Epoch 42/50
352/352 [==============================] - 25s 72ms/step - loss: 0.3655 - accuracy: 0.8744 - val_loss: 1.3022 - val_accuracy: 0.6454
Epoch 43/50
352/352 [==============================] - 25s 72ms/step - loss: 0.3025 - accuracy: 0.9006 - val_loss: 2.4816 - val_accuracy: 0.6374
Epoch 44/50
352/352 [==============================] - 25s 71ms/step - loss: 0.3954 - accuracy: 0.8812 - val_loss: 1.9328 - val_accuracy: 0.5966
Epoch 45/50
352/352 [==============================] - 25s 72ms/step - loss: 0.2679 - accuracy: 0.9201 - val_loss: 1.4435 - val_accuracy: 0.6718
Epoch 46/50
352/352 [==============================] - 25s 72ms/step - loss: 0.1874 - accuracy: 0.9412 - val_loss: 1.6017 - val_accuracy: 0.6692
Epoch 47/50
352/352 [==============================] - 25s 72ms/step - loss: 0.2566 - accuracy: 0.9237 - val_loss: 1.3472 - val_accuracy: 0.6420
Epoch 48/50
352/352 [==============================] - 25s 72ms/step - loss: 0.2684 - accuracy: 0.9089 - val_loss: 1.4494 - val_accuracy: 0.6674
Epoch 49/50
352/352 [==============================] - 25s 71ms/step - loss: 0.2447 - accuracy: 0.9268 - val_loss: 2.4799 - val_accuracy: 0.5198
Epoch 50/50
352/352 [==============================] - 25s 72ms/step - loss: 0.4610 - accuracy: 0.8575 - val_loss: 1.2436 - val_accuracy: 0.6902
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Part 2. Cifar-10</strong></p>
<p>The prepared (downloaded) ResNet50 model had an accuracy compared to Shallow &#39;Covnet&#39;. Overall, it has more poor results, in comparison to the constructed &#39;ResNet&#39;. Plot shows unstable results that demonstrate unbalanced performance of the model.</p>
<table>
<thead><tr>
<th></th>
<th>Train Accuracy</th>
<th>Train Loss</th>
<th>Val Accuracy</th>
<th>Val Loss</th>
<th>Test Accuracy</th>
<th>Test Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fast Training, &quot;Shallow&quot; CovNet</td>
<td>0.9723</td>
<td>0.0789</td>
<td>0.6656</td>
<td>2.5531</td>
<td>0.6713</td>
<td>2.6417</td>
<td>2 </td>
</tr>
<tr>
<td>Fast Training of ResNet</td>
<td>0.9890</td>
<td>0.0708</td>
<td>0.7800</td>
<td>1.1889</td>
<td>0.7792</td>
<td>1.1887</td>
<td>15</td>
</tr>
<tr>
<td>Fast Training of ResNet (prepared model ResNet50)</td>
<td>0.8575</td>
<td>0.4610</td>
<td>0.6902</td>
<td>1.2436</td>
<td>0.6920</td>
<td>1.2080</td>
<td>25</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet (prepared model ResNet50) | <font color="#6D8AC3"> Test Loss and Test Accuracy</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Test Accuracy/Loss</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test loss: </span><span class="si">{score[0]}</span><span class="s1"> / Test accuracy: </span><span class="si">{score[1]}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 1.207942247390747 / Test accuracy: 0.6919999718666077
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> ResNet (prepared model ResNet50) | <font color="#6D8AC3"> Plot train/validation loss and accuracy</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># plot the loss and accuracy</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 2.2 Fast training of ResNet<a rel="noopener" class="anchor-link" href="#Task-2.2-Fast-training-of-ResNet">&#182;</a></h3><p><em>(weight ~10%)</em></p>
<p>In this task, you will experiment with different ways to reduce the time for training your ResNet on CIFAR10. There are different ways to speed up neural network training; below are two ideas. Please select at least one idea to implement. Explain the experiment steps and report the final performance and training time.</p>
<h4>Option 1. Learning rate schedule<a rel="noopener" class="anchor-link" href="#Option-1.-Learning-rate-schedule">&#182;</a></h4><p>Use a learning rate schedule for the training. Some popular learning rate schedules include</p>
<ul>
<li>the Step Decay learning rate (e.g., see <a rel="noopener" href="https://github.com/kuangliu/pytorch-cifar">here</a>)</li>
<li><a rel="noopener" href="https://arxiv.org/abs/1506.01186">Cyclical learning rates</a></li>
<li><a rel="noopener" href="https://openreview.net/forum?id=rJg8TeSFDH">The exponential learning rate</a> </li>
</ul>
<p>Also, Keras provides <a rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules">some convenient functions</a> that you can use.</p>
<h4>Option 2. Look ahead optimiser<a rel="noopener" class="anchor-link" href="#Option-2.-Look-ahead-optimiser">&#182;</a></h4><p>Read <a rel="noopener" href="https://arxiv.org/abs/1907.08610">this paper</a> and implement the Lookahead optimiser.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> Fast Training of ResNet | <font color="#6D8AC3">  + Step Decay Learning Rate</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>
<p>Select the first custom ResNet model over loaded ResNet50 due to higher test accuracy.</p>
<p>Libraries, Data Preproccesing, Train/Validation Split, Sample Selection</p>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[72]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">pyplot</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="o">%</span><span class="k">tensorflow_version</span> 2.x
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>


<span class="n">cifar10</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span>

<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="c1"># Max value in the image set:</span>
<span class="nb">max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>

<span class="c1">#Normalization:</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>

<span class="c1">#Labels to cathegorical</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="k">import</span> <span class="n">to_categorical</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>


<span class="c1"># Split the train and the validation set for the fitting</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="n">train_images</span><span class="p">,</span> <span class="n">val_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_images shape: &quot;</span><span class="p">,</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_images shape: &quot;</span><span class="p">,</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_images shape: &quot;</span><span class="p">,</span><span class="n">val_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_labels shape: &quot;</span><span class="p">,</span><span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_lables shape: &quot;</span><span class="p">,</span><span class="n">test_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_labels shape :&quot;</span><span class="p">,</span><span class="n">val_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>2.4.1
2.4.0
0
255
(50000, 32, 32, 3)
(10000, 32, 32, 3)
train_images shape:  (45000, 32, 32, 3)
test_images shape:  (10000, 32, 32, 3)
val_images shape:  (5000, 32, 32, 3)
train_labels shape:  (45000, 10)
test_lables shape:  (10000, 10)
val_labels shape : (5000, 10)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> Fast Training of ResNet | <font color="#6D8AC3"> + Step Decay Learning Rate: <font color="#C3D2F2">Create, Compile the Model</font></font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2">
<hr/>

</font></font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2">
</font></font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2">
</font></font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[73]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">partial</span>

<span class="n">DefaultConv2D</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">,</span> 
                        <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
                        <span class="p">)</span>

<span class="n">DefaultSeparableConv2D</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">SeparableConv2D</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                 <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">,</span> 
                                 <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                 <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">DepthwiseResidualUnit</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">main_layers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">DefaultSeparableConv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">),</span>
            <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">DefaultSeparableConv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">),</span>
            <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">skip_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">strides</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">skip_layers</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">DefaultConv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">),</span>
                <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_layers</span><span class="p">:</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
        <span class="n">skip_Z</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">skip_layers</span><span class="p">:</span>
            <span class="n">skip_Z</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">skip_Z</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">Z</span> <span class="o">+</span> <span class="n">skip_Z</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="n">prev_filters</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">prev_filters</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">prev_filters</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">prev_filters</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">prev_filters</span><span class="p">]</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">DefaultConv2D</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                        <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">DepthwiseResidualUnit</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">DepthwiseResidualUnit</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">DepthwiseResidualUnit</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">DepthwiseResidualUnit</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: &quot;sequential_6&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_10 (Conv2D)           (None, 32, 32, 64)        1728      
_________________________________________________________________
depthwise_residual_unit_4 (D (None, 32, 32, 64)        9856      
_________________________________________________________________
depthwise_residual_unit_5 (D (None, 16, 16, 128)       36032     
_________________________________________________________________
depthwise_residual_unit_6 (D (None, 8, 8, 256)         137600    
_________________________________________________________________
depthwise_residual_unit_7 (D (None, 4, 4, 256)         204288    
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 10)                2570      
=================================================================
Total params: 392,074
Trainable params: 387,978
Non-trainable params: 4,096
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> Fast Training of ResNet | <font color="#6D8AC3"> + Step Decay Learning Rate (0.01) | <font color="#C3D2F2">Train the Model</font></font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2">
<hr/>

</font></font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2">
</font></font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2">
</font></font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[74]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">BATCH_SIZE</span><span class="o">=</span><span class="mi">128</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
352/352 [==============================] - 16s 43ms/step - loss: 6.7580 - accuracy: 0.3055 - val_loss: 4.9281 - val_accuracy: 0.2652
Epoch 2/50
352/352 [==============================] - 15s 42ms/step - loss: 4.1482 - accuracy: 0.4868 - val_loss: 3.8327 - val_accuracy: 0.4320
Epoch 3/50
352/352 [==============================] - 15s 42ms/step - loss: 3.5151 - accuracy: 0.5362 - val_loss: 3.5050 - val_accuracy: 0.4734
Epoch 4/50
352/352 [==============================] - 15s 42ms/step - loss: 3.1608 - accuracy: 0.5635 - val_loss: 3.0896 - val_accuracy: 0.5374
Epoch 5/50
352/352 [==============================] - 15s 41ms/step - loss: 2.9208 - accuracy: 0.5844 - val_loss: 3.0167 - val_accuracy: 0.5078
Epoch 6/50
352/352 [==============================] - 15s 41ms/step - loss: 2.7579 - accuracy: 0.5973 - val_loss: 3.0530 - val_accuracy: 0.4816
Epoch 7/50
352/352 [==============================] - 15s 42ms/step - loss: 2.6122 - accuracy: 0.6141 - val_loss: 2.8543 - val_accuracy: 0.5086
Epoch 8/50
352/352 [==============================] - 15s 42ms/step - loss: 2.4978 - accuracy: 0.6241 - val_loss: 2.8049 - val_accuracy: 0.4942
Epoch 9/50
352/352 [==============================] - 15s 42ms/step - loss: 2.4163 - accuracy: 0.6293 - val_loss: 2.5813 - val_accuracy: 0.5438
Epoch 10/50
352/352 [==============================] - 15s 41ms/step - loss: 2.3291 - accuracy: 0.6426 - val_loss: 2.4708 - val_accuracy: 0.5708
Epoch 11/50
352/352 [==============================] - 15s 42ms/step - loss: 2.2678 - accuracy: 0.6440 - val_loss: 2.4224 - val_accuracy: 0.5766
Epoch 12/50
352/352 [==============================] - 15s 42ms/step - loss: 2.1997 - accuracy: 0.6561 - val_loss: 2.4108 - val_accuracy: 0.5638
Epoch 13/50
352/352 [==============================] - 15s 42ms/step - loss: 2.1437 - accuracy: 0.6602 - val_loss: 2.3964 - val_accuracy: 0.5566
Epoch 14/50
352/352 [==============================] - 15s 42ms/step - loss: 2.0827 - accuracy: 0.6699 - val_loss: 2.2818 - val_accuracy: 0.5878
Epoch 15/50
352/352 [==============================] - 15s 42ms/step - loss: 2.0435 - accuracy: 0.6746 - val_loss: 2.2885 - val_accuracy: 0.5756
Epoch 16/50
352/352 [==============================] - 15s 42ms/step - loss: 2.0003 - accuracy: 0.6787 - val_loss: 2.3649 - val_accuracy: 0.5432
Epoch 17/50
352/352 [==============================] - 15s 42ms/step - loss: 1.9594 - accuracy: 0.6865 - val_loss: 2.2192 - val_accuracy: 0.5842
Epoch 18/50
352/352 [==============================] - 15s 42ms/step - loss: 1.9244 - accuracy: 0.6907 - val_loss: 2.1614 - val_accuracy: 0.5926
Epoch 19/50
352/352 [==============================] - 15s 41ms/step - loss: 1.8947 - accuracy: 0.6931 - val_loss: 2.1440 - val_accuracy: 0.5934
Epoch 20/50
352/352 [==============================] - 15s 42ms/step - loss: 1.8663 - accuracy: 0.6959 - val_loss: 2.1271 - val_accuracy: 0.5828
Epoch 21/50
352/352 [==============================] - 15s 42ms/step - loss: 1.8396 - accuracy: 0.6992 - val_loss: 2.1054 - val_accuracy: 0.5900
Epoch 22/50
352/352 [==============================] - 15s 42ms/step - loss: 1.8067 - accuracy: 0.7070 - val_loss: 2.0759 - val_accuracy: 0.5964
Epoch 23/50
352/352 [==============================] - 15s 42ms/step - loss: 1.7772 - accuracy: 0.7107 - val_loss: 2.0613 - val_accuracy: 0.5936
Epoch 24/50
352/352 [==============================] - 15s 42ms/step - loss: 1.7610 - accuracy: 0.7088 - val_loss: 2.0589 - val_accuracy: 0.5958
Epoch 25/50
352/352 [==============================] - 15s 41ms/step - loss: 1.7286 - accuracy: 0.7177 - val_loss: 2.0227 - val_accuracy: 0.6006
Epoch 26/50
352/352 [==============================] - 15s 42ms/step - loss: 1.7084 - accuracy: 0.7199 - val_loss: 2.0123 - val_accuracy: 0.5906
Epoch 27/50
352/352 [==============================] - 15s 42ms/step - loss: 1.6870 - accuracy: 0.7239 - val_loss: 1.9887 - val_accuracy: 0.5990
Epoch 28/50
352/352 [==============================] - 15s 42ms/step - loss: 1.6672 - accuracy: 0.7276 - val_loss: 1.9868 - val_accuracy: 0.5986
Epoch 29/50
352/352 [==============================] - 15s 42ms/step - loss: 1.6534 - accuracy: 0.7285 - val_loss: 1.9907 - val_accuracy: 0.5962
Epoch 30/50
352/352 [==============================] - 15s 42ms/step - loss: 1.6268 - accuracy: 0.7303 - val_loss: 1.9506 - val_accuracy: 0.6032
Epoch 31/50
352/352 [==============================] - 15s 42ms/step - loss: 1.6100 - accuracy: 0.7367 - val_loss: 1.9385 - val_accuracy: 0.6024
Epoch 32/50
352/352 [==============================] - 15s 41ms/step - loss: 1.5957 - accuracy: 0.7354 - val_loss: 1.9361 - val_accuracy: 0.6024
Epoch 33/50
352/352 [==============================] - 15s 42ms/step - loss: 1.5764 - accuracy: 0.7402 - val_loss: 1.9305 - val_accuracy: 0.6060
Epoch 34/50
352/352 [==============================] - 15s 42ms/step - loss: 1.5598 - accuracy: 0.7424 - val_loss: 1.9185 - val_accuracy: 0.6028
Epoch 35/50
352/352 [==============================] - 15s 42ms/step - loss: 1.5462 - accuracy: 0.7469 - val_loss: 1.9514 - val_accuracy: 0.5984
Epoch 36/50
352/352 [==============================] - 15s 42ms/step - loss: 1.5369 - accuracy: 0.7429 - val_loss: 1.8821 - val_accuracy: 0.6084
Epoch 37/50
352/352 [==============================] - 15s 42ms/step - loss: 1.5078 - accuracy: 0.7541 - val_loss: 1.9313 - val_accuracy: 0.5958
Epoch 38/50
352/352 [==============================] - 15s 42ms/step - loss: 1.4974 - accuracy: 0.7542 - val_loss: 1.8817 - val_accuracy: 0.6040
Epoch 39/50
352/352 [==============================] - 15s 42ms/step - loss: 1.4834 - accuracy: 0.7580 - val_loss: 1.8601 - val_accuracy: 0.6094
Epoch 40/50
352/352 [==============================] - 15s 42ms/step - loss: 1.4763 - accuracy: 0.7588 - val_loss: 1.8548 - val_accuracy: 0.6096
Epoch 41/50
352/352 [==============================] - 15s 42ms/step - loss: 1.4615 - accuracy: 0.7571 - val_loss: 1.8385 - val_accuracy: 0.6108
Epoch 42/50
352/352 [==============================] - 15s 41ms/step - loss: 1.4445 - accuracy: 0.7654 - val_loss: 1.8427 - val_accuracy: 0.6070
Epoch 43/50
352/352 [==============================] - 15s 41ms/step - loss: 1.4444 - accuracy: 0.7608 - val_loss: 1.8245 - val_accuracy: 0.6166
Epoch 44/50
352/352 [==============================] - 15s 42ms/step - loss: 1.4326 - accuracy: 0.7639 - val_loss: 1.8308 - val_accuracy: 0.6126
Epoch 45/50
352/352 [==============================] - 15s 42ms/step - loss: 1.4168 - accuracy: 0.7654 - val_loss: 1.8250 - val_accuracy: 0.6090
Epoch 46/50
352/352 [==============================] - 15s 42ms/step - loss: 1.4039 - accuracy: 0.7695 - val_loss: 1.8011 - val_accuracy: 0.6098
Epoch 47/50
352/352 [==============================] - 15s 42ms/step - loss: 1.4040 - accuracy: 0.7696 - val_loss: 1.8054 - val_accuracy: 0.6086
Epoch 48/50
352/352 [==============================] - 15s 42ms/step - loss: 1.3813 - accuracy: 0.7734 - val_loss: 1.8589 - val_accuracy: 0.5978
Epoch 49/50
352/352 [==============================] - 15s 42ms/step - loss: 1.3750 - accuracy: 0.7720 - val_loss: 1.7850 - val_accuracy: 0.6126
Epoch 50/50
352/352 [==============================] - 15s 42ms/step - loss: 1.3682 - accuracy: 0.7780 - val_loss: 1.8001 - val_accuracy: 0.6126
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[75]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Test Accuracy/Loss</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test loss: </span><span class="si">{score[0]}</span><span class="s1"> / Test accuracy: </span><span class="si">{score[1]}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 1.790257215499878 / Test accuracy: 0.6064000129699707
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Experiments with different Learning Rate:<a rel="noopener" class="anchor-link" href="#Experiments-with-different-Learning-Rate:">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Learning rate of 0.05 gives the best result on the test set:</p>
<p>(based on one experiment above and three below)</p>
<hr/>
<table>
<thead><tr>
<th>Learning Rate</th>
<th>Train Accuracy</th>
<th>Train Loss</th>
<th>Val Accuracy</th>
<th>Val Loss</th>
<th>Test Accuracy</th>
<th>Test Loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.01</td>
<td>0.7780</td>
<td>1.3682</td>
<td>0.6126</td>
<td>1.8001</td>
<td>0.6064</td>
<td>1.7903</td>
</tr>
<tr>
<td>0.05</td>
<td>0.9986</td>
<td>0.1061</td>
<td>0.7344</td>
<td>0.9807</td>
<td>0.7371</td>
<td>0.9719</td>
</tr>
<tr>
<td>0.09</td>
<td>0.9486</td>
<td>0.3470</td>
<td>0.6232</td>
<td>1.3595</td>
<td>0.6289</td>
<td>1.3455</td>
</tr>
<tr>
<td>0.001</td>
<td>0.9959</td>
<td>0.2140</td>
<td>0.6618</td>
<td>1.2074</td>
<td>0.6717</td>
<td>1.1910</td>
</tr>
</tbody>
</table>
<p>Training time is 15s per epoch for every experiment.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> Fast Training of ResNet | <font color="#6D8AC3"> + Step Decay Learning Rate (0.05)</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[76]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">BATCH_SIZE</span><span class="o">=</span><span class="mi">128</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
352/352 [==============================] - 16s 43ms/step - loss: 3.8322 - accuracy: 0.2720 - val_loss: 2.2880 - val_accuracy: 0.2772
Epoch 2/50
352/352 [==============================] - 15s 42ms/step - loss: 1.6646 - accuracy: 0.4580 - val_loss: 1.8176 - val_accuracy: 0.3940
Epoch 3/50
352/352 [==============================] - 15s 42ms/step - loss: 1.3883 - accuracy: 0.5436 - val_loss: 1.6633 - val_accuracy: 0.4326
Epoch 4/50
352/352 [==============================] - 15s 42ms/step - loss: 1.2045 - accuracy: 0.6094 - val_loss: 1.3132 - val_accuracy: 0.5610
Epoch 5/50
352/352 [==============================] - 15s 42ms/step - loss: 1.0670 - accuracy: 0.6644 - val_loss: 1.2900 - val_accuracy: 0.5922
Epoch 6/50
352/352 [==============================] - 15s 42ms/step - loss: 0.9708 - accuracy: 0.6990 - val_loss: 1.1943 - val_accuracy: 0.6208
Epoch 7/50
352/352 [==============================] - 15s 42ms/step - loss: 0.8871 - accuracy: 0.7303 - val_loss: 1.2678 - val_accuracy: 0.6026
Epoch 8/50
352/352 [==============================] - 15s 42ms/step - loss: 0.8207 - accuracy: 0.7516 - val_loss: 1.0991 - val_accuracy: 0.6530
Epoch 9/50
352/352 [==============================] - 15s 42ms/step - loss: 0.7701 - accuracy: 0.7694 - val_loss: 1.0730 - val_accuracy: 0.6630
Epoch 10/50
352/352 [==============================] - 15s 42ms/step - loss: 0.7253 - accuracy: 0.7859 - val_loss: 1.0375 - val_accuracy: 0.6844
Epoch 11/50
352/352 [==============================] - 15s 42ms/step - loss: 0.6637 - accuracy: 0.8127 - val_loss: 1.0272 - val_accuracy: 0.6874
Epoch 12/50
352/352 [==============================] - 15s 42ms/step - loss: 0.6258 - accuracy: 0.8264 - val_loss: 1.0994 - val_accuracy: 0.6640
Epoch 13/50
352/352 [==============================] - 15s 42ms/step - loss: 0.5888 - accuracy: 0.8386 - val_loss: 1.0374 - val_accuracy: 0.6944
Epoch 14/50
352/352 [==============================] - 15s 42ms/step - loss: 0.5467 - accuracy: 0.8555 - val_loss: 1.1295 - val_accuracy: 0.6672
Epoch 15/50
352/352 [==============================] - 15s 42ms/step - loss: 0.5162 - accuracy: 0.8711 - val_loss: 1.2041 - val_accuracy: 0.6496
Epoch 16/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4872 - accuracy: 0.8807 - val_loss: 1.0278 - val_accuracy: 0.7024
Epoch 17/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4471 - accuracy: 0.8974 - val_loss: 1.0271 - val_accuracy: 0.6998
Epoch 18/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4166 - accuracy: 0.9091 - val_loss: 0.9735 - val_accuracy: 0.7228
Epoch 19/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3988 - accuracy: 0.9156 - val_loss: 1.0971 - val_accuracy: 0.6912
Epoch 20/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3703 - accuracy: 0.9282 - val_loss: 1.0046 - val_accuracy: 0.7136
Epoch 21/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3489 - accuracy: 0.9369 - val_loss: 0.9787 - val_accuracy: 0.7190
Epoch 22/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3264 - accuracy: 0.9453 - val_loss: 1.0154 - val_accuracy: 0.7102
Epoch 23/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3077 - accuracy: 0.9538 - val_loss: 0.9856 - val_accuracy: 0.7190
Epoch 24/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2915 - accuracy: 0.9577 - val_loss: 1.0268 - val_accuracy: 0.7116
Epoch 25/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2741 - accuracy: 0.9623 - val_loss: 1.0099 - val_accuracy: 0.7178
Epoch 26/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2584 - accuracy: 0.9687 - val_loss: 1.0024 - val_accuracy: 0.7160
Epoch 27/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2476 - accuracy: 0.9728 - val_loss: 0.9774 - val_accuracy: 0.7250
Epoch 28/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2333 - accuracy: 0.9768 - val_loss: 1.0908 - val_accuracy: 0.7056
Epoch 29/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2206 - accuracy: 0.9798 - val_loss: 0.9913 - val_accuracy: 0.7234
Epoch 30/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2052 - accuracy: 0.9856 - val_loss: 1.0323 - val_accuracy: 0.7086
Epoch 31/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1970 - accuracy: 0.9877 - val_loss: 0.9949 - val_accuracy: 0.7190
Epoch 32/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1902 - accuracy: 0.9885 - val_loss: 1.0091 - val_accuracy: 0.7310
Epoch 33/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1794 - accuracy: 0.9912 - val_loss: 0.9909 - val_accuracy: 0.7246
Epoch 34/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1761 - accuracy: 0.9921 - val_loss: 1.0274 - val_accuracy: 0.7210
Epoch 35/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1659 - accuracy: 0.9929 - val_loss: 0.9883 - val_accuracy: 0.7326
Epoch 36/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1568 - accuracy: 0.9951 - val_loss: 1.0145 - val_accuracy: 0.7286
Epoch 37/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1524 - accuracy: 0.9952 - val_loss: 1.0060 - val_accuracy: 0.7200
Epoch 38/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1477 - accuracy: 0.9955 - val_loss: 0.9869 - val_accuracy: 0.7248
Epoch 39/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1426 - accuracy: 0.9970 - val_loss: 0.9942 - val_accuracy: 0.7348
Epoch 40/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1370 - accuracy: 0.9964 - val_loss: 0.9989 - val_accuracy: 0.7282
Epoch 41/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1348 - accuracy: 0.9969 - val_loss: 1.0221 - val_accuracy: 0.7252
Epoch 42/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1285 - accuracy: 0.9975 - val_loss: 0.9954 - val_accuracy: 0.7290
Epoch 43/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1277 - accuracy: 0.9979 - val_loss: 0.9744 - val_accuracy: 0.7362
Epoch 44/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1222 - accuracy: 0.9974 - val_loss: 1.0134 - val_accuracy: 0.7274
Epoch 45/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1185 - accuracy: 0.9982 - val_loss: 1.0438 - val_accuracy: 0.7216
Epoch 46/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1160 - accuracy: 0.9984 - val_loss: 0.9927 - val_accuracy: 0.7312
Epoch 47/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1114 - accuracy: 0.9988 - val_loss: 0.9845 - val_accuracy: 0.7350
Epoch 48/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1095 - accuracy: 0.9986 - val_loss: 1.0079 - val_accuracy: 0.7294
Epoch 49/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1073 - accuracy: 0.9984 - val_loss: 1.0266 - val_accuracy: 0.7320
Epoch 50/50
352/352 [==============================] - 15s 42ms/step - loss: 0.1061 - accuracy: 0.9986 - val_loss: 0.9807 - val_accuracy: 0.7344
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Test Accuracy/Loss</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test loss: </span><span class="si">{score[0]}</span><span class="s1"> / Test accuracy: </span><span class="si">{score[1]}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 0.9718724489212036 / Test accuracy: 0.7371000051498413
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> Fast Training of ResNet | <font color="#6D8AC3"> + Step Decay Learning Rate (0.09)</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[78]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">BATCH_SIZE</span><span class="o">=</span><span class="mi">128</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.09</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
352/352 [==============================] - 16s 42ms/step - loss: 10.5890 - accuracy: 0.2384 - val_loss: 2.4095 - val_accuracy: 0.1860
Epoch 2/50
352/352 [==============================] - 15s 42ms/step - loss: 1.7845 - accuracy: 0.4119 - val_loss: 2.2563 - val_accuracy: 0.2244
Epoch 3/50
352/352 [==============================] - 15s 42ms/step - loss: 1.5520 - accuracy: 0.4819 - val_loss: 1.6738 - val_accuracy: 0.4422
Epoch 4/50
352/352 [==============================] - 15s 42ms/step - loss: 1.4254 - accuracy: 0.5279 - val_loss: 1.6528 - val_accuracy: 0.4556
Epoch 5/50
352/352 [==============================] - 15s 42ms/step - loss: 1.3466 - accuracy: 0.5550 - val_loss: 1.7461 - val_accuracy: 0.4590
Epoch 6/50
352/352 [==============================] - 15s 42ms/step - loss: 1.2716 - accuracy: 0.5861 - val_loss: 1.3602 - val_accuracy: 0.5570
Epoch 7/50
352/352 [==============================] - 15s 42ms/step - loss: 1.2224 - accuracy: 0.6089 - val_loss: 1.5118 - val_accuracy: 0.5112
Epoch 8/50
352/352 [==============================] - 15s 42ms/step - loss: 1.1810 - accuracy: 0.6256 - val_loss: 1.4889 - val_accuracy: 0.5158
Epoch 9/50
352/352 [==============================] - 15s 42ms/step - loss: 1.1400 - accuracy: 0.6380 - val_loss: 1.3823 - val_accuracy: 0.5586
Epoch 10/50
352/352 [==============================] - 15s 42ms/step - loss: 1.1127 - accuracy: 0.6495 - val_loss: 1.2623 - val_accuracy: 0.6042
Epoch 11/50
352/352 [==============================] - 15s 42ms/step - loss: 1.0670 - accuracy: 0.6679 - val_loss: 1.6143 - val_accuracy: 0.4922
Epoch 12/50
352/352 [==============================] - 15s 42ms/step - loss: 1.0214 - accuracy: 0.6863 - val_loss: 1.4409 - val_accuracy: 0.5398
Epoch 13/50
352/352 [==============================] - 15s 42ms/step - loss: 0.9878 - accuracy: 0.6945 - val_loss: 1.4226 - val_accuracy: 0.5524
Epoch 14/50
352/352 [==============================] - 15s 42ms/step - loss: 0.9644 - accuracy: 0.7072 - val_loss: 1.2310 - val_accuracy: 0.6160
Epoch 15/50
352/352 [==============================] - 15s 42ms/step - loss: 0.9369 - accuracy: 0.7159 - val_loss: 1.2377 - val_accuracy: 0.6092
Epoch 16/50
352/352 [==============================] - 15s 42ms/step - loss: 0.9051 - accuracy: 0.7328 - val_loss: 1.2824 - val_accuracy: 0.6108
Epoch 17/50
352/352 [==============================] - 15s 42ms/step - loss: 0.8827 - accuracy: 0.7368 - val_loss: 1.2498 - val_accuracy: 0.6062
Epoch 18/50
352/352 [==============================] - 15s 42ms/step - loss: 0.8477 - accuracy: 0.7516 - val_loss: 1.3328 - val_accuracy: 0.5974
Epoch 19/50
352/352 [==============================] - 15s 42ms/step - loss: 0.8255 - accuracy: 0.7608 - val_loss: 1.3574 - val_accuracy: 0.5844
Epoch 20/50
352/352 [==============================] - 15s 42ms/step - loss: 0.8049 - accuracy: 0.7702 - val_loss: 1.1807 - val_accuracy: 0.6392
Epoch 21/50
352/352 [==============================] - 15s 42ms/step - loss: 0.7744 - accuracy: 0.7797 - val_loss: 1.2229 - val_accuracy: 0.6316
Epoch 22/50
352/352 [==============================] - 15s 42ms/step - loss: 0.7575 - accuracy: 0.7891 - val_loss: 1.7139 - val_accuracy: 0.4966
Epoch 23/50
352/352 [==============================] - 15s 42ms/step - loss: 0.7388 - accuracy: 0.7944 - val_loss: 1.2242 - val_accuracy: 0.6274
Epoch 24/50
352/352 [==============================] - 15s 42ms/step - loss: 0.7122 - accuracy: 0.8065 - val_loss: 1.3266 - val_accuracy: 0.6058
Epoch 25/50
352/352 [==============================] - 15s 42ms/step - loss: 0.6928 - accuracy: 0.8141 - val_loss: 1.2185 - val_accuracy: 0.6422
Epoch 26/50
352/352 [==============================] - 15s 42ms/step - loss: 0.6684 - accuracy: 0.8239 - val_loss: 1.2160 - val_accuracy: 0.6382
Epoch 27/50
352/352 [==============================] - 15s 42ms/step - loss: 0.6484 - accuracy: 0.8316 - val_loss: 1.2353 - val_accuracy: 0.6318
Epoch 28/50
352/352 [==============================] - 15s 42ms/step - loss: 0.6322 - accuracy: 0.8392 - val_loss: 1.2732 - val_accuracy: 0.6228
Epoch 29/50
352/352 [==============================] - 15s 42ms/step - loss: 0.6163 - accuracy: 0.8463 - val_loss: 1.5434 - val_accuracy: 0.5588
Epoch 30/50
352/352 [==============================] - 15s 42ms/step - loss: 0.6010 - accuracy: 0.8530 - val_loss: 1.2064 - val_accuracy: 0.6436
Epoch 31/50
352/352 [==============================] - 15s 42ms/step - loss: 0.5839 - accuracy: 0.8602 - val_loss: 1.2328 - val_accuracy: 0.6392
Epoch 32/50
352/352 [==============================] - 15s 42ms/step - loss: 0.5642 - accuracy: 0.8647 - val_loss: 1.2627 - val_accuracy: 0.6282
Epoch 33/50
352/352 [==============================] - 15s 42ms/step - loss: 0.5466 - accuracy: 0.8710 - val_loss: 1.4033 - val_accuracy: 0.6086
Epoch 34/50
352/352 [==============================] - 15s 42ms/step - loss: 0.5310 - accuracy: 0.8832 - val_loss: 1.2491 - val_accuracy: 0.6354
Epoch 35/50
352/352 [==============================] - 15s 42ms/step - loss: 0.5161 - accuracy: 0.8830 - val_loss: 1.2082 - val_accuracy: 0.6546
Epoch 36/50
352/352 [==============================] - 15s 42ms/step - loss: 0.5011 - accuracy: 0.8906 - val_loss: 1.2488 - val_accuracy: 0.6450
Epoch 37/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4984 - accuracy: 0.8931 - val_loss: 1.2352 - val_accuracy: 0.6458
Epoch 38/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4762 - accuracy: 0.8992 - val_loss: 1.4055 - val_accuracy: 0.5990
Epoch 39/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4592 - accuracy: 0.9074 - val_loss: 1.3135 - val_accuracy: 0.6368
Epoch 40/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4452 - accuracy: 0.9134 - val_loss: 1.2185 - val_accuracy: 0.6498
Epoch 41/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4363 - accuracy: 0.9160 - val_loss: 1.3462 - val_accuracy: 0.6248
Epoch 42/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4249 - accuracy: 0.9218 - val_loss: 1.2820 - val_accuracy: 0.6368
Epoch 43/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4157 - accuracy: 0.9247 - val_loss: 1.2339 - val_accuracy: 0.6516
Epoch 44/50
352/352 [==============================] - 15s 42ms/step - loss: 0.4034 - accuracy: 0.9283 - val_loss: 1.2729 - val_accuracy: 0.6446
Epoch 45/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3893 - accuracy: 0.9336 - val_loss: 1.2771 - val_accuracy: 0.6452
Epoch 46/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3827 - accuracy: 0.9380 - val_loss: 1.3044 - val_accuracy: 0.6414
Epoch 47/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3746 - accuracy: 0.9389 - val_loss: 1.3299 - val_accuracy: 0.6292
Epoch 48/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3657 - accuracy: 0.9414 - val_loss: 1.2565 - val_accuracy: 0.6516
Epoch 49/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3585 - accuracy: 0.9451 - val_loss: 1.3640 - val_accuracy: 0.6252
Epoch 50/50
352/352 [==============================] - 15s 42ms/step - loss: 0.3470 - accuracy: 0.9486 - val_loss: 1.3595 - val_accuracy: 0.6232
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[79]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Test Accuracy/Loss</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test loss: </span><span class="si">{score[0]}</span><span class="s1"> / Test accuracy: </span><span class="si">{score[1]}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 1.3455281257629395 / Test accuracy: 0.6288999915122986
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> Fast Training of ResNet | <font color="#6D8AC3"> + Step Decay Learning Rate (0.001)</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[80]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">BATCH_SIZE</span><span class="o">=</span><span class="mi">128</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
352/352 [==============================] - 17s 44ms/step - loss: 0.3553 - accuracy: 0.9422 - val_loss: 1.2098 - val_accuracy: 0.6628
Epoch 2/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2719 - accuracy: 0.9823 - val_loss: 1.1987 - val_accuracy: 0.6648
Epoch 3/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2527 - accuracy: 0.9889 - val_loss: 1.1993 - val_accuracy: 0.6622
Epoch 4/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2452 - accuracy: 0.9909 - val_loss: 1.2025 - val_accuracy: 0.6636
Epoch 5/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2379 - accuracy: 0.9928 - val_loss: 1.2017 - val_accuracy: 0.6596
Epoch 6/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2355 - accuracy: 0.9916 - val_loss: 1.2053 - val_accuracy: 0.6610
Epoch 7/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2326 - accuracy: 0.9937 - val_loss: 1.2018 - val_accuracy: 0.6626
Epoch 8/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2310 - accuracy: 0.9935 - val_loss: 1.2066 - val_accuracy: 0.6608
Epoch 9/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2302 - accuracy: 0.9938 - val_loss: 1.2057 - val_accuracy: 0.6608
Epoch 10/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2310 - accuracy: 0.9925 - val_loss: 1.2014 - val_accuracy: 0.6620
Epoch 11/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2298 - accuracy: 0.9934 - val_loss: 1.2023 - val_accuracy: 0.6640
Epoch 12/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2254 - accuracy: 0.9947 - val_loss: 1.2028 - val_accuracy: 0.6644
Epoch 13/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2246 - accuracy: 0.9946 - val_loss: 1.2001 - val_accuracy: 0.6634
Epoch 14/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2263 - accuracy: 0.9937 - val_loss: 1.2057 - val_accuracy: 0.6642
Epoch 15/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2247 - accuracy: 0.9944 - val_loss: 1.2064 - val_accuracy: 0.6646
Epoch 16/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2250 - accuracy: 0.9936 - val_loss: 1.2095 - val_accuracy: 0.6632
Epoch 17/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2238 - accuracy: 0.9943 - val_loss: 1.2070 - val_accuracy: 0.6636
Epoch 18/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2211 - accuracy: 0.9953 - val_loss: 1.2058 - val_accuracy: 0.6628
Epoch 19/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2218 - accuracy: 0.9946 - val_loss: 1.2089 - val_accuracy: 0.6636
Epoch 20/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2216 - accuracy: 0.9955 - val_loss: 1.2061 - val_accuracy: 0.6638
Epoch 21/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2209 - accuracy: 0.9948 - val_loss: 1.2067 - val_accuracy: 0.6656
Epoch 22/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2214 - accuracy: 0.9941 - val_loss: 1.2068 - val_accuracy: 0.6616
Epoch 23/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2197 - accuracy: 0.9951 - val_loss: 1.2045 - val_accuracy: 0.6624
Epoch 24/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2192 - accuracy: 0.9956 - val_loss: 1.2034 - val_accuracy: 0.6620
Epoch 25/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2193 - accuracy: 0.9955 - val_loss: 1.2055 - val_accuracy: 0.6630
Epoch 26/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2208 - accuracy: 0.9952 - val_loss: 1.2059 - val_accuracy: 0.6634
Epoch 27/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2191 - accuracy: 0.9956 - val_loss: 1.2072 - val_accuracy: 0.6628
Epoch 28/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2207 - accuracy: 0.9948 - val_loss: 1.2041 - val_accuracy: 0.6630
Epoch 29/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2173 - accuracy: 0.9954 - val_loss: 1.2062 - val_accuracy: 0.6612
Epoch 30/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2182 - accuracy: 0.9947 - val_loss: 1.2041 - val_accuracy: 0.6628
Epoch 31/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2154 - accuracy: 0.9956 - val_loss: 1.2047 - val_accuracy: 0.6640
Epoch 32/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2175 - accuracy: 0.9956 - val_loss: 1.2068 - val_accuracy: 0.6622
Epoch 33/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2171 - accuracy: 0.9949 - val_loss: 1.2061 - val_accuracy: 0.6632
Epoch 34/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2174 - accuracy: 0.9952 - val_loss: 1.2059 - val_accuracy: 0.6600
Epoch 35/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2171 - accuracy: 0.9951 - val_loss: 1.2077 - val_accuracy: 0.6626
Epoch 36/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2151 - accuracy: 0.9959 - val_loss: 1.2046 - val_accuracy: 0.6640
Epoch 37/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2153 - accuracy: 0.9951 - val_loss: 1.2047 - val_accuracy: 0.6626
Epoch 38/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2158 - accuracy: 0.9955 - val_loss: 1.2057 - val_accuracy: 0.6626
Epoch 39/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2164 - accuracy: 0.9952 - val_loss: 1.2064 - val_accuracy: 0.6624
Epoch 40/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2117 - accuracy: 0.9962 - val_loss: 1.2048 - val_accuracy: 0.6622
Epoch 41/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2162 - accuracy: 0.9948 - val_loss: 1.2050 - val_accuracy: 0.6624
Epoch 42/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2148 - accuracy: 0.9960 - val_loss: 1.2070 - val_accuracy: 0.6614
Epoch 43/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2146 - accuracy: 0.9959 - val_loss: 1.2061 - val_accuracy: 0.6610
Epoch 44/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2151 - accuracy: 0.9956 - val_loss: 1.2053 - val_accuracy: 0.6624
Epoch 45/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2137 - accuracy: 0.9954 - val_loss: 1.2072 - val_accuracy: 0.6624
Epoch 46/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2150 - accuracy: 0.9957 - val_loss: 1.2060 - val_accuracy: 0.6600
Epoch 47/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2125 - accuracy: 0.9963 - val_loss: 1.2063 - val_accuracy: 0.6612
Epoch 48/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2160 - accuracy: 0.9952 - val_loss: 1.2062 - val_accuracy: 0.6618
Epoch 49/50
352/352 [==============================] - 15s 42ms/step - loss: 0.2128 - accuracy: 0.9965 - val_loss: 1.2060 - val_accuracy: 0.6614
Epoch 50/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2140 - accuracy: 0.9959 - val_loss: 1.2074 - val_accuracy: 0.6618
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[81]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Test Accuracy/Loss</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test loss: </span><span class="si">{score[0]}</span><span class="s1"> / Test accuracy: </span><span class="si">{score[1]}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 1.1910353899002075 / Test accuracy: 0.6717000007629395
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># plot the loss and accuracy</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Validation accuracy show average overfitting.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> Fast Training of ResNet | <font color="#6D8AC3"> Step Decay Learning Rate  + Look Ahead Optimizer</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[84]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install tensorflow-addons
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_addons</span> <span class="k">as</span> <span class="nn">tfa</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting tensorflow-addons
  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)
     |████████████████████████████████| 686kB 8.1MB/s 
Requirement already satisfied: typeguard&gt;=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)
Installing collected packages: tensorflow-addons
Successfully installed tensorflow-addons-0.13.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[86]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">BATCH_SIZE</span><span class="o">=</span><span class="mi">128</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="n">tfa</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Lookahead</span><span class="p">(</span><span class="n">opt</span><span class="p">),</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
352/352 [==============================] - 19s 44ms/step - loss: 0.5236 - accuracy: 0.8898 - val_loss: 1.1251 - val_accuracy: 0.6872
Epoch 2/50
352/352 [==============================] - 15s 43ms/step - loss: 0.4194 - accuracy: 0.9175 - val_loss: 1.3151 - val_accuracy: 0.6440
Epoch 3/50
352/352 [==============================] - 15s 44ms/step - loss: 0.3916 - accuracy: 0.9222 - val_loss: 1.1116 - val_accuracy: 0.7002
Epoch 4/50
352/352 [==============================] - 15s 43ms/step - loss: 0.3873 - accuracy: 0.9235 - val_loss: 1.4101 - val_accuracy: 0.6470
Epoch 5/50
352/352 [==============================] - 15s 43ms/step - loss: 0.3747 - accuracy: 0.9257 - val_loss: 1.4918 - val_accuracy: 0.6210
Epoch 6/50
352/352 [==============================] - 15s 43ms/step - loss: 0.3583 - accuracy: 0.9323 - val_loss: 1.1614 - val_accuracy: 0.6972
Epoch 7/50
352/352 [==============================] - 15s 43ms/step - loss: 0.3412 - accuracy: 0.9373 - val_loss: 2.9664 - val_accuracy: 0.3710
Epoch 8/50
352/352 [==============================] - 15s 43ms/step - loss: 0.3445 - accuracy: 0.9356 - val_loss: 1.5500 - val_accuracy: 0.6468
Epoch 9/50
352/352 [==============================] - 15s 43ms/step - loss: 0.3265 - accuracy: 0.9433 - val_loss: 1.2129 - val_accuracy: 0.6956
Epoch 10/50
352/352 [==============================] - 15s 43ms/step - loss: 0.3102 - accuracy: 0.9497 - val_loss: 1.3929 - val_accuracy: 0.6586
Epoch 11/50
352/352 [==============================] - 15s 43ms/step - loss: 0.3057 - accuracy: 0.9503 - val_loss: 1.4418 - val_accuracy: 0.6570
Epoch 12/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2958 - accuracy: 0.9561 - val_loss: 1.4108 - val_accuracy: 0.6478
Epoch 13/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2869 - accuracy: 0.9572 - val_loss: 1.5094 - val_accuracy: 0.6498
Epoch 14/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2809 - accuracy: 0.9591 - val_loss: 1.6338 - val_accuracy: 0.6186
Epoch 15/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2708 - accuracy: 0.9623 - val_loss: 1.2464 - val_accuracy: 0.7024
Epoch 16/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2635 - accuracy: 0.9629 - val_loss: 1.6151 - val_accuracy: 0.6490
Epoch 17/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2607 - accuracy: 0.9636 - val_loss: 1.4399 - val_accuracy: 0.6704
Epoch 18/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2605 - accuracy: 0.9623 - val_loss: 1.3621 - val_accuracy: 0.6808
Epoch 19/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2463 - accuracy: 0.9679 - val_loss: 1.8177 - val_accuracy: 0.6138
Epoch 20/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2353 - accuracy: 0.9707 - val_loss: 1.6609 - val_accuracy: 0.6442
Epoch 21/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2484 - accuracy: 0.9648 - val_loss: 1.3278 - val_accuracy: 0.6982
Epoch 22/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2305 - accuracy: 0.9724 - val_loss: 1.7996 - val_accuracy: 0.6318
Epoch 23/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2431 - accuracy: 0.9660 - val_loss: 1.4344 - val_accuracy: 0.6846
Epoch 24/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2324 - accuracy: 0.9698 - val_loss: 1.3335 - val_accuracy: 0.6988
Epoch 25/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2043 - accuracy: 0.9800 - val_loss: 1.6704 - val_accuracy: 0.6484
Epoch 26/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2157 - accuracy: 0.9735 - val_loss: 1.7968 - val_accuracy: 0.6298
Epoch 27/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2163 - accuracy: 0.9739 - val_loss: 1.4227 - val_accuracy: 0.6898
Epoch 28/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2084 - accuracy: 0.9759 - val_loss: 1.6411 - val_accuracy: 0.6550
Epoch 29/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2229 - accuracy: 0.9714 - val_loss: 1.5401 - val_accuracy: 0.6784
Epoch 30/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1897 - accuracy: 0.9829 - val_loss: 1.5064 - val_accuracy: 0.6830
Epoch 31/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2015 - accuracy: 0.9758 - val_loss: 1.6811 - val_accuracy: 0.6536
Epoch 32/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1970 - accuracy: 0.9776 - val_loss: 2.1181 - val_accuracy: 0.6114
Epoch 33/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1888 - accuracy: 0.9810 - val_loss: 1.6134 - val_accuracy: 0.6700
Epoch 34/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1988 - accuracy: 0.9755 - val_loss: 1.7584 - val_accuracy: 0.6568
Epoch 35/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1820 - accuracy: 0.9826 - val_loss: 1.6705 - val_accuracy: 0.6606
Epoch 36/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1944 - accuracy: 0.9753 - val_loss: 1.6293 - val_accuracy: 0.6890
Epoch 37/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1848 - accuracy: 0.9816 - val_loss: 1.5064 - val_accuracy: 0.6906
Epoch 38/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1633 - accuracy: 0.9868 - val_loss: 2.7647 - val_accuracy: 0.5526
Epoch 39/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2362 - accuracy: 0.9581 - val_loss: 1.7747 - val_accuracy: 0.6542
Epoch 40/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1788 - accuracy: 0.9839 - val_loss: 1.4427 - val_accuracy: 0.6970
Epoch 41/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1327 - accuracy: 0.9949 - val_loss: 4.2484 - val_accuracy: 0.4062
Epoch 42/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2491 - accuracy: 0.9540 - val_loss: 1.4243 - val_accuracy: 0.7016
Epoch 43/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1730 - accuracy: 0.9864 - val_loss: 1.6400 - val_accuracy: 0.6676
Epoch 44/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1398 - accuracy: 0.9913 - val_loss: 1.8269 - val_accuracy: 0.6486
Epoch 45/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1715 - accuracy: 0.9772 - val_loss: 1.6839 - val_accuracy: 0.6828
Epoch 46/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1885 - accuracy: 0.9781 - val_loss: 2.0846 - val_accuracy: 0.5936
Epoch 47/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1485 - accuracy: 0.9897 - val_loss: 2.0109 - val_accuracy: 0.6272
Epoch 48/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1264 - accuracy: 0.9925 - val_loss: 2.7595 - val_accuracy: 0.5110
Epoch 49/50
352/352 [==============================] - 15s 43ms/step - loss: 0.2686 - accuracy: 0.9439 - val_loss: 1.9972 - val_accuracy: 0.5886
Epoch 50/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1592 - accuracy: 0.9887 - val_loss: 1.4914 - val_accuracy: 0.7032
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The ResNet Model with Step Decay Learning Rate and Look Ahead Optimize has some improvements and shows results comparable to the original ResNet. However, it is not higher than original result that might be because of the effect of Step Decay Learning Rate.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Test Accuracy/Loss</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test loss: </span><span class="si">{score[0]}</span><span class="s1"> / Test accuracy: </span><span class="si">{score[1]}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 1.5075163841247559 / Test accuracy: 0.7008000016212463
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[88]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># plot the loss and accuracy</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Fast Training | <font color="#90AEE9"> Fast Training of ResNet | <font color="#6D8AC3"> + Look Ahead Optimizer</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[89]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">BATCH_SIZE</span><span class="o">=</span><span class="mi">128</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="n">tfa</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Lookahead</span><span class="p">(</span><span class="n">opt</span><span class="p">),</span>
             <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
352/352 [==============================] - 19s 44ms/step - loss: 0.1342 - accuracy: 0.9944 - val_loss: 1.3168 - val_accuracy: 0.7308
Epoch 2/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1094 - accuracy: 0.9996 - val_loss: 1.2984 - val_accuracy: 0.7344
Epoch 3/50
352/352 [==============================] - 15s 43ms/step - loss: 0.1003 - accuracy: 0.9998 - val_loss: 1.2994 - val_accuracy: 0.7322
Epoch 4/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0929 - accuracy: 0.9999 - val_loss: 1.2923 - val_accuracy: 0.7336
Epoch 5/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 1.2911 - val_accuracy: 0.7350
Epoch 6/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 1.2912 - val_accuracy: 0.7358
Epoch 7/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 1.2907 - val_accuracy: 0.7334
Epoch 8/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 1.2837 - val_accuracy: 0.7348
Epoch 9/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 1.2785 - val_accuracy: 0.7350
Epoch 10/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 1.2761 - val_accuracy: 0.7352
Epoch 11/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 1.2757 - val_accuracy: 0.7336
Epoch 12/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 1.2745 - val_accuracy: 0.7344
Epoch 13/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 1.2722 - val_accuracy: 0.7348
Epoch 14/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 1.2703 - val_accuracy: 0.7318
Epoch 15/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 1.2702 - val_accuracy: 0.7326
Epoch 16/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 1.2698 - val_accuracy: 0.7340
Epoch 17/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 1.2646 - val_accuracy: 0.7336
Epoch 18/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 1.2647 - val_accuracy: 0.7332
Epoch 19/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 1.2655 - val_accuracy: 0.7366
Epoch 20/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0320 - accuracy: 0.9999 - val_loss: 1.2625 - val_accuracy: 0.7330
Epoch 21/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.2628 - val_accuracy: 0.7338
Epoch 22/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.2597 - val_accuracy: 0.7322
Epoch 23/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.2595 - val_accuracy: 0.7318
Epoch 24/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 1.2582 - val_accuracy: 0.7328
Epoch 25/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.2567 - val_accuracy: 0.7336
Epoch 26/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.2549 - val_accuracy: 0.7308
Epoch 27/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.2643 - val_accuracy: 0.7338
Epoch 28/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.2563 - val_accuracy: 0.7330
Epoch 29/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.2469 - val_accuracy: 0.7320
Epoch 30/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.2554 - val_accuracy: 0.7324
Epoch 31/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.2454 - val_accuracy: 0.7310
Epoch 32/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.2605 - val_accuracy: 0.7292
Epoch 33/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.2489 - val_accuracy: 0.7274
Epoch 34/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.2412 - val_accuracy: 0.7308
Epoch 35/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.2428 - val_accuracy: 0.7316
Epoch 36/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.2423 - val_accuracy: 0.7348
Epoch 37/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.2535 - val_accuracy: 0.7278
Epoch 38/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.2889 - val_accuracy: 0.7224
Epoch 39/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.2457 - val_accuracy: 0.7310
Epoch 40/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3279 - val_accuracy: 0.7154
Epoch 41/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.2629 - val_accuracy: 0.7258
Epoch 42/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.2399 - val_accuracy: 0.7296
Epoch 43/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.2510 - val_accuracy: 0.7290
Epoch 44/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.2479 - val_accuracy: 0.7326
Epoch 45/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.2470 - val_accuracy: 0.7290
Epoch 46/50
352/352 [==============================] - 15s 42ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3312 - val_accuracy: 0.7140
Epoch 47/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.2386 - val_accuracy: 0.7314
Epoch 48/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.2567 - val_accuracy: 0.7286
Epoch 49/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.2884 - val_accuracy: 0.7254
Epoch 50/50
352/352 [==============================] - 15s 43ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.2495 - val_accuracy: 0.7314
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[90]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Test Accuracy/Loss</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test loss: </span><span class="si">{score[0]}</span><span class="s1"> / Test accuracy: </span><span class="si">{score[1]}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 1.2409528493881226 / Test accuracy: 0.7373999953269958
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[91]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># plot the loss and accuracy</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Task 2.3 Performance comparison<a rel="noopener" class="anchor-link" href="#Task-2.3-Performance-comparison">&#182;</a></h3><p><em>(weight ~3%)</em></p>
<p>Based on the above experiments, which method or which combination of methods result in the best accuracy with the same training time.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Part 2. Cifar-10</strong></p>
<table>
<thead><tr>
<th></th>
<th>Train Accuracy</th>
<th>Train Loss</th>
<th>Val Accuracy</th>
<th>Val Loss</th>
<th>Test Accuracy</th>
<th>Test Loss</th>
<th>Training Time (ms per step)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fast Training, &quot;Shallow&quot; CovNet</td>
<td>0.9723</td>
<td>0.0789</td>
<td>0.6656</td>
<td>2.5531</td>
<td>0.6713</td>
<td>2.6417</td>
<td>2 </td>
</tr>
<tr>
<td>Fast Training of ResNet</td>
<td>0.9890</td>
<td>0.0708</td>
<td>0.7800</td>
<td>1.1889</td>
<td>0.7792</td>
<td>1.1887</td>
<td>15</td>
</tr>
<tr>
<td>Fast Training of ResNet (prepared model ResNet50)</td>
<td>0.8575</td>
<td>0.4610</td>
<td>0.6902</td>
<td>1.2436</td>
<td>0.6920</td>
<td>1.2080</td>
<td>25</td>
</tr>
<tr>
<td>Fast Training of ResNet,+ Step Decay Learning Rate (0.05)</td>
<td>0.9986</td>
<td>0.1061</td>
<td>0.7344</td>
<td>0.9807</td>
<td>0.7371</td>
<td>0.9719</td>
<td>15</td>
</tr>
<tr>
<td>Fast Training of ResNet,+ Step Decay Learning Rate (0.05) + Look Ahead Optimizer</td>
<td>0.9887</td>
<td>0.1592</td>
<td>0.7032</td>
<td>1.4914</td>
<td>0.7008</td>
<td>1.5075</td>
<td>15</td>
</tr>
<tr>
<td>Fast Training of ResNet,+ Look Ahead Optimizer</td>
<td>1.0000</td>
<td>0.0113</td>
<td>0.7314</td>
<td>1.2495</td>
<td>0.7374</td>
<td>1.2410</td>
<td>15</td>
</tr>
</tbody>
</table>
<p>The ResNet model with only Look Ahead Optimize and without use of Step Decay Learning Rate has the highest accuracy amongst all ResNet Models. It has 81.22% for the Test accuracy and the lowest test loss under 1. It support the statement that learning rate on Cifar-10 is not very effective and it is the same as for the Fashion Mnist in the Assignment 1.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The &quot;Shallow&quot; CovNet model showed the most poor performance as expected.</p>
<p>The original ResNet in these experiments demostrated the highest test accuracy of 78%, while Model with Step Decay Leaning Rate and Model with Look Ahead Optimizer have the second highest teast accuracy about 74%.</p>
<p>On itself Learning rate does not show much improvement and this is compararable the learning rate behaviour in the previous assignment.</p>
<p>In the future the effect of learning rate on Look Ahead Optimizer can be investigated in more details. It is possible that the way learning rate perform individually is diffrent to its performance with other optimizers. It is possible the for better results of Look Ahead Optimizer, Learning Rate should be different.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Task 3 (<strong>HD level task</strong>) Research on new models<a rel="noopener" class="anchor-link" href="#Task-3-(HD-level-task)-Research-on-new-models">&#182;</a></h2><p><em>(weight ~10%)</em></p>
<p>Today, ResNet has become a very mature ConvNet architecture. In this task, you will research one recent ConvNet architecture. You may choose an architecture from the reference list below.</p>
<p>Write a short report for your research, covering these points:</p>
<ul>
<li>Identify the main issues that your chosen architecture aims to address. (For example, does it try to reduce the number of parameters or to speed up the training?)</li>
<li>What measures the architecture used to reduce the number of parameters, or reducing the training cost, or improving the model performance?</li>
</ul>
<p>Implement the architecture and compare its performance on CIFAR10 with ResNet. You may include your implementation, experiments, and analyses here in this notebook.</p>
<p><strong>References</strong>:</p>
<ol>
<li>Huang G, Liu Z, Van Der Maaten L, Weinberger KQ. <em>Densely connected convolutional networks</em>. In Proceedings of the IEEE conference on computer vision and pattern recognition 2017 (pp. 4700-4708).</li>
<li>Zhang X, Zhou X, Lin M, Sun J. <em>Shufflenet: An extremely efficient convolutional neural network for mobile devices</em>. In Proceedings of the IEEE conference on computer vision and pattern recognition 2018 (pp. 6848-6856).</li>
<li>Tan M, Le Q. <em>Efficientnet: Rethinking model scaling for convolutional neural networks</em>. In International Conference on Machine Learning 2019 May 24 (pp. 6105-6114). PMLR.</li>
<li>Hu J, Shen L, Sun G. <em>Squeeze-and-excitation networks</em>. In Proceedings of the IEEE conference on computer vision and pattern recognition 2018 (pp. 7132-7141).</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Write a short report for your research, covering these points: <a rel="noopener" class="anchor-link" href="#Write-a-short-report-for-your-research,-covering-these-points:-">&#182;</a></h2><h5><strong>DenseNet</strong><a rel="noopener" class="anchor-link" href="#DenseNet">&#182;</a></h5><h5>Huang G, Liu Z, Van Der Maaten L, Weinberger KQ. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition 2017 (pp. 4700-4708).<a rel="noopener" class="anchor-link" href="#Huang-G,-Liu-Z,-Van-Der-Maaten-L,-Weinberger-KQ.-Densely-connected-convolutional-networks.-In-Proceedings-of-the-IEEE-conference-on-computer-vision-and-pattern-recognition-2017-(pp.-4700-4708).">&#182;</a></h5><hr/>
<p><font color="#8796C7"><strong>Identify the main issues that your chosen architecture aims to address. (For example, does it try to reduce the number of parameters or to speed up the training?)</strong></font></p><font color="#8796C7">
<ul>
<li>It alleviate the vanishing-gradient problem </li>
<li>It strengthen feature propagation</li>
<li>It encourage feature reuse. In particular, it yields condensed models that are easy to train and highly parameterefficient. Concatenating feature-maps learned by different layers increases variation in th</li>
<li>It reduce the number of parameters to speed up training.</li>
<li>It requires less computation to achieve high performance.</li>
</ul>
<p><font color="#8796C7"><strong>What measures the architecture used to reduce the number of parameters, or reducing the training cost, or improving the model performance?</strong></font></p><font color="#8796C7">
<ul>
<li><p>Requires fewer parameters since no need to relearn redundant feature-maps.</p>
</li>
<li><p>DenseNet differentiates between information that is added to the network and that is preserved.
DenseNet layers are very narrow (e.g., 12 filters per layer), adding only a small set of feature-maps to the “collective knowledge” of the network and keep the  emaining featuremaps unchanged—and the final classifier.</p>
</li>
<li><p>Improved flow of information and gradients makes the training easier.</p>
</li>
<li><p>Each layer has direct access to the gradients from the
loss function and the original input signal, leading to an implicit deep supervision, this helps training.</p>
</li>
</ul>
<p><strong>Different Dense connectivity pattern</strong></p>
<ul>
<li>Direct connections from any layer to all subsequent layers. The layer receives the feature-maps of all preceding layers. For ease of implementation, we concatenate the multiple inputs layers into a single tensor.</li>
</ul>
<p><strong>Composite function</strong></p>
<ul>
<li>It is a three consecutive operations: batch normalization, a rectified linear unit (ReLU) and a 3 &#215; 3 convolution (Conv).</li>
</ul>
<p><strong>Pooling layers</strong></p>
<ul>
<li>The concatenation operation used in is not viable when the size of feature-maps changes. The down-sampling layers that change the size of feature-maps. For it devide the network into multiple densely connected dense blocks. The layers between blocks as transition layers, which do convolution and pooling. The transition layers consist of a batch normalization layer and an 1&#215;1 convolutional layer followed by a 2&#215;2 average pooling layer.</li>
</ul>
<p><strong>Growth rate</strong></p>
<ul>
<li>The  DenseNet have very narrow layers, e.g., k = 12. The hyperparameter k as the growth rate of the network. Relatively small growth rate is sufficient because each layer has access
to all the preceding feature-maps in its block and, therefore,
to the network’s “collective knowledge”. 
Each layer adds k feature-maps of its own to this state. The growth
rate regulates how much new information each layer contributes to the global state. The global state: there is no need
to replicate it from layer to layer.</li>
</ul>
<p><strong>Compression</strong></p>
<ul>
<li>To further improve model compactness, reduce the number of feature-maps at transition layers. If a dense block contains m feature-maps, we let
the following transition layer generate ⌊θm⌋ output featuremaps, where 0 &lt;θ ≤1 is referred to as the compression factor. When θ = 1, the number of feature-maps across transition layers remains unchanged. We refer the DenseNet with
θ &lt; 1 as DenseNet-C, and we set θ = 0.5 in our experiment.
When both the bottleneck and transition layers with θ &lt; 1
are used, we refer to our model as DenseNet-BC.</li>
</ul>
<p><strong>Capacity.</strong></p>
<ul>
<li>Without compression or bottleneck layers the error drops as the number of parameters increases. This suggests that DenseNets can utilize the increased representational power of bigger and deeper models. It also indicates that they do not suffer from overfitting or the optimization
difficulties of residual networks.</li>
</ul>
<p><strong>Parameter Efficiency.</strong></p>
<ul>
<li>DenseNets utilize parameters more efficiently than ResNets. The DenseNet with bottleneck structure and dimension reduction at transition layers is particularly parameter-efficient.</li>
</ul>
<p><strong>Overfitting.</strong></p>
<ul>
<li>Less tendency to overfit due to the higher number of the more efficient use of parameters.</li>
</ul>

</font></font></div><font color="#8796C7"><font color="#8796C7">
</font></font></div><font color="#8796C7"><font color="#8796C7">
</font></font></div><font color="#8796C7"><font color="#8796C7">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Research on New Models | <font color="#90AEE9"> DenseNet | <font color="#6D8AC3"> Import Libraries</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[92]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">GlobalAveragePooling2D</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">concatenate</span><span class="p">,</span> <span class="n">AveragePooling2D</span>
<span class="kn">from</span> <span class="nn">keras.layers.convolutional</span> <span class="k">import</span> <span class="n">Conv2D</span>
<span class="kn">from</span> <span class="nn">keras.layers.core</span> <span class="k">import</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.layers.normalization</span> <span class="k">import</span> <span class="n">BatchNormalization</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="k">import</span> <span class="n">Adam</span>


<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">pyplot</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="o">%</span><span class="k">tensorflow_version</span> 2.x
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>2.4.1
2.4.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Research on New Models | <font color="#90AEE9"> DenseNet | <font color="#6D8AC3"> Import Dataset + Preprocessing</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[93]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">cifar10</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span>

<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Max value in the image set:</span>
<span class="nb">max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">train_images</span><span class="p">)</span>

<span class="c1">#Normalization:</span>
<span class="n">train_images</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">test_images</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span>

<span class="c1">#Labels to cathegorical</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="k">import</span> <span class="n">to_categorical</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="c1"># Split the train and the validation set for the fitting</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="n">train_images</span><span class="p">,</span> <span class="n">val_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_images shape: &quot;</span><span class="p">,</span><span class="n">train_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_images shape: &quot;</span><span class="p">,</span><span class="n">test_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_images shape: &quot;</span><span class="p">,</span><span class="n">val_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_labels shape: &quot;</span><span class="p">,</span><span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_lables shape: &quot;</span><span class="p">,</span><span class="n">test_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;val_labels shape :&quot;</span><span class="p">,</span><span class="n">val_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.0
1.0
(50000, 32, 32, 3)
(10000, 32, 32, 3)
train_images shape:  (45000, 32, 32, 3)
test_images shape:  (10000, 32, 32, 3)
val_images shape:  (5000, 32, 32, 3)
train_labels shape:  (45000, 10)
test_lables shape:  (10000, 10)
val_labels shape : (5000, 10)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Research on New Models | <font color="#90AEE9"> DenseNet | <font color="#6D8AC3"> Define DenseNet Model (from research paper)</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Huang G, Liu Z, Van Der Maaten L, Weinberger KQ. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition 2017 (pp. 4700-4708).</p>
<p><a rel="noopener" href="https://arxiv.org/pdf/1608.06993.pdf">https://arxiv.org/pdf/1608.06993.pdf</a></p>
<p>Code Sample based on the reference paper:</p>
<p><a rel="noopener" href="https://github.com/arnavdodiedo/DenseNet-Fashion-MNIST/blob/master/fashion-mnist-net.py">https://github.com/arnavdodiedo/DenseNet-Fashion-MNIST/blob/master/fashion-mnist-net.py</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[94]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">DenseNet</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dense_blocks</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dense_layers</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">growth_rate</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">nb_classes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">dropout_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bottleneck</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">40</span><span class="p">):</span>

        <span class="c1"># Checks</span>
        <span class="k">if</span> <span class="n">nb_classes</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span> <span class="s1">&#39;Please define number of classes (e.g. num_classes=10). This is required for final softmax.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">compression</span> <span class="o">&lt;=</span> <span class="mf">0.0</span> <span class="ow">or</span> <span class="n">compression</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Compression have to be a value between 0.0 and 1.0.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">dense_layers</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dense_layers</span><span class="p">)</span> <span class="o">!=</span> <span class="n">dense_blocks</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="s1">&#39;Number of dense blocks have to be same length to specified layers&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">dense_layers</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">dense_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">depth</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="mi">3</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">bottleneck</span><span class="p">:</span>
                <span class="n">dense_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dense_layers</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">dense_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">dense_layers</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dense_blocks</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dense_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">dense_layers</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dense_blocks</span><span class="p">)]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dense_blocks</span> <span class="o">=</span> <span class="n">dense_blocks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense_layers</span> <span class="o">=</span> <span class="n">dense_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">growth_rate</span> <span class="o">=</span> <span class="n">growth_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck</span> <span class="o">=</span> <span class="n">bottleneck</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compression</span> <span class="o">=</span> <span class="n">compression</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_classes</span> <span class="o">=</span> <span class="n">nb_classes</span>
        
    <span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">img_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;img_input&#39;</span><span class="p">)</span>
        <span class="n">nb_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">growth_rate</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">growth_rate</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> 
                   <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> 
                   <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">))(</span><span class="n">img_input</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense_blocks</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">nb_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_layers</span><span class="p">[</span><span class="n">block</span><span class="p">],</span> <span class="n">nb_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">growth_rate</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">)</span>
            
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nb_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">compression</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">)</span>
            <span class="n">nb_channels</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">nb_channels</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">compression</span><span class="p">)</span>
            
        <span class="n">x</span><span class="p">,</span> <span class="n">nb_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">nb_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">growth_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">)</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nb_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">img_input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">prediction</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;densenet&#39;</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">dense_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">nb_layers</span><span class="p">,</span> <span class="n">nb_channels</span><span class="p">,</span> <span class="n">growth_rate</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bottleneck</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">4</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_layers</span><span class="p">):</span>
            <span class="n">cb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convolution_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">growth_rate</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">bottleneck</span><span class="p">)</span>
            <span class="n">nb_channels</span> <span class="o">+=</span> <span class="n">growth_rate</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">([</span><span class="n">cb</span><span class="p">,</span><span class="n">x</span><span class="p">])</span>
            
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">nb_channels</span>
    
    <span class="k">def</span> <span class="nf">convolution_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">nb_channels</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bottleneck</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">4</span><span class="p">):</span>       

        <span class="c1"># Bottleneck</span>
        <span class="k">if</span> <span class="n">bottleneck</span><span class="p">:</span>
            <span class="n">bottleneckWidth</span> <span class="o">=</span> <span class="mi">4</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">nb_channels</span> <span class="o">*</span> <span class="n">bottleneckWidth</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                     <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
            <span class="c1"># Dropout</span>
            <span class="k">if</span> <span class="n">dropout_rate</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Standard (BN-ReLU-Conv)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">nb_channels</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Dropout</span>
        <span class="k">if</span> <span class="n">dropout_rate</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">transition_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">nb_channels</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">4</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">nb_channels</span> <span class="o">*</span> <span class="n">compression</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
                                 <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Adding dropout</span>
        <span class="k">if</span> <span class="n">dropout_rate</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">AveragePooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
    
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Research on New Models | <font color="#90AEE9"> DenseNet | <font color="#6D8AC3"> Define the Model</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[95]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">densenet</span> <span class="o">=</span> <span class="n">DenseNet</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">nb_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">35</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Research on New Models | <font color="#90AEE9"> DenseNet | <font color="#6D8AC3"> Compile and Fit Model</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[96]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">BATCH_SIZE</span><span class="o">=</span><span class="mi">128</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">densenet</span><span class="o">.</span><span class="n">build_model</span><span class="p">()</span>
<span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mi">1</span><span class="n">E</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">08</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>   <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s1">&#39;D:\codes\python\densenet\Fashion-MNIST\weights.h5&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
352/352 [==============================] - 72s 183ms/step - loss: 1.6629 - accuracy: 0.4439 - val_loss: 2.4728 - val_accuracy: 0.2688
Epoch 2/50
352/352 [==============================] - 61s 173ms/step - loss: 1.0401 - accuracy: 0.6622 - val_loss: 1.1576 - val_accuracy: 0.6274
Epoch 3/50
352/352 [==============================] - 61s 174ms/step - loss: 0.8373 - accuracy: 0.7364 - val_loss: 1.4358 - val_accuracy: 0.5690
Epoch 4/50
352/352 [==============================] - 61s 174ms/step - loss: 0.6859 - accuracy: 0.7886 - val_loss: 1.2512 - val_accuracy: 0.6498
Epoch 5/50
352/352 [==============================] - 61s 173ms/step - loss: 0.5991 - accuracy: 0.8178 - val_loss: 0.9897 - val_accuracy: 0.6990
Epoch 6/50
352/352 [==============================] - 61s 174ms/step - loss: 0.5156 - accuracy: 0.8487 - val_loss: 1.0822 - val_accuracy: 0.6748
Epoch 7/50
352/352 [==============================] - 61s 174ms/step - loss: 0.4667 - accuracy: 0.8650 - val_loss: 0.9333 - val_accuracy: 0.7364
Epoch 8/50
352/352 [==============================] - 61s 174ms/step - loss: 0.4056 - accuracy: 0.8850 - val_loss: 0.8233 - val_accuracy: 0.7574
Epoch 9/50
352/352 [==============================] - 61s 173ms/step - loss: 0.3794 - accuracy: 0.8942 - val_loss: 0.7570 - val_accuracy: 0.7752
Epoch 10/50
352/352 [==============================] - 61s 174ms/step - loss: 0.3342 - accuracy: 0.9109 - val_loss: 0.9671 - val_accuracy: 0.7458
Epoch 11/50
352/352 [==============================] - 61s 174ms/step - loss: 0.3012 - accuracy: 0.9224 - val_loss: 0.8229 - val_accuracy: 0.7694
Epoch 12/50
352/352 [==============================] - 61s 173ms/step - loss: 0.2810 - accuracy: 0.9304 - val_loss: 0.9609 - val_accuracy: 0.7308
Epoch 13/50
352/352 [==============================] - 61s 173ms/step - loss: 0.2589 - accuracy: 0.9362 - val_loss: 0.8217 - val_accuracy: 0.7690
Epoch 14/50
352/352 [==============================] - 61s 174ms/step - loss: 0.2377 - accuracy: 0.9443 - val_loss: 1.1353 - val_accuracy: 0.7326
Epoch 15/50
352/352 [==============================] - 61s 173ms/step - loss: 0.2289 - accuracy: 0.9463 - val_loss: 0.9857 - val_accuracy: 0.7826
Epoch 16/50
352/352 [==============================] - 61s 173ms/step - loss: 0.2140 - accuracy: 0.9527 - val_loss: 0.6475 - val_accuracy: 0.8328
Epoch 17/50
352/352 [==============================] - 61s 173ms/step - loss: 0.1985 - accuracy: 0.9593 - val_loss: 0.8428 - val_accuracy: 0.8036
Epoch 18/50
352/352 [==============================] - 61s 173ms/step - loss: 0.1813 - accuracy: 0.9640 - val_loss: 0.7983 - val_accuracy: 0.7896
Epoch 19/50
352/352 [==============================] - 61s 173ms/step - loss: 0.1748 - accuracy: 0.9661 - val_loss: 1.4568 - val_accuracy: 0.7080
Epoch 20/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1735 - accuracy: 0.9680 - val_loss: 1.1222 - val_accuracy: 0.7702
Epoch 21/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1662 - accuracy: 0.9689 - val_loss: 1.8331 - val_accuracy: 0.6962
Epoch 22/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1623 - accuracy: 0.9708 - val_loss: 1.3384 - val_accuracy: 0.7084
Epoch 23/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1570 - accuracy: 0.9720 - val_loss: 0.9802 - val_accuracy: 0.7920
Epoch 24/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1512 - accuracy: 0.9747 - val_loss: 0.8711 - val_accuracy: 0.8090
Epoch 25/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1429 - accuracy: 0.9782 - val_loss: 1.0509 - val_accuracy: 0.7804
Epoch 26/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1427 - accuracy: 0.9769 - val_loss: 1.0122 - val_accuracy: 0.8040
Epoch 27/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1400 - accuracy: 0.9792 - val_loss: 1.1864 - val_accuracy: 0.7642
Epoch 28/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1434 - accuracy: 0.9768 - val_loss: 1.0413 - val_accuracy: 0.7924
Epoch 29/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1359 - accuracy: 0.9806 - val_loss: 1.0967 - val_accuracy: 0.7816
Epoch 30/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1294 - accuracy: 0.9819 - val_loss: 0.8053 - val_accuracy: 0.8272
Epoch 31/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1341 - accuracy: 0.9811 - val_loss: 1.1430 - val_accuracy: 0.7926
Epoch 32/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1357 - accuracy: 0.9791 - val_loss: 1.0258 - val_accuracy: 0.7856
Epoch 33/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1356 - accuracy: 0.9793 - val_loss: 1.1636 - val_accuracy: 0.7828
Epoch 34/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1271 - accuracy: 0.9825 - val_loss: 1.0044 - val_accuracy: 0.7942
Epoch 35/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1244 - accuracy: 0.9831 - val_loss: 1.1165 - val_accuracy: 0.7828
Epoch 36/50
352/352 [==============================] - 61s 173ms/step - loss: 0.1279 - accuracy: 0.9821 - val_loss: 1.3095 - val_accuracy: 0.7758
Epoch 37/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1200 - accuracy: 0.9846 - val_loss: 1.2876 - val_accuracy: 0.7828
Epoch 38/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1212 - accuracy: 0.9842 - val_loss: 1.0311 - val_accuracy: 0.7896
Epoch 39/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1202 - accuracy: 0.9838 - val_loss: 1.0502 - val_accuracy: 0.7856
Epoch 40/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1184 - accuracy: 0.9841 - val_loss: 0.8275 - val_accuracy: 0.8212
Epoch 41/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1245 - accuracy: 0.9832 - val_loss: 1.3163 - val_accuracy: 0.7722
Epoch 42/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1088 - accuracy: 0.9874 - val_loss: 1.1773 - val_accuracy: 0.7844
Epoch 43/50
352/352 [==============================] - 61s 173ms/step - loss: 0.1260 - accuracy: 0.9813 - val_loss: 1.8601 - val_accuracy: 0.7192
Epoch 44/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1129 - accuracy: 0.9862 - val_loss: 0.9554 - val_accuracy: 0.8188
Epoch 45/50
352/352 [==============================] - 61s 173ms/step - loss: 0.1130 - accuracy: 0.9854 - val_loss: 1.3690 - val_accuracy: 0.7506
Epoch 46/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1260 - accuracy: 0.9816 - val_loss: 1.2969 - val_accuracy: 0.7632
Epoch 47/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1058 - accuracy: 0.9888 - val_loss: 1.3474 - val_accuracy: 0.7808
Epoch 48/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1049 - accuracy: 0.9885 - val_loss: 1.4049 - val_accuracy: 0.7644
Epoch 49/50
352/352 [==============================] - 61s 173ms/step - loss: 0.1109 - accuracy: 0.9866 - val_loss: 0.8852 - val_accuracy: 0.8184
Epoch 50/50
352/352 [==============================] - 61s 174ms/step - loss: 0.1129 - accuracy: 0.9860 - val_loss: 0.8240 - val_accuracy: 0.8358
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Part 3. DenseNet on Cifar-10</strong></p>
<p>The DenseNet fitting took 50 minutes. About 1 minute per epoch.</p>
<p>The DenseNet shows average performance with test accuracy of 83.72%</p>
<table>
<thead><tr>
<th></th>
<th>Train Accuracy</th>
<th>Train Loss</th>
<th>Val Accuracy</th>
<th>Val Loss</th>
<th>Test Accuracy</th>
<th>Test Loss</th>
<th>Training Time per epoch</th>
</tr>
</thead>
<tbody>
<tr>
<td>DenseNet</td>
<td>0.9860</td>
<td>0.1129</td>
<td>0.8353</td>
<td>0.8240</td>
<td>0.8372</td>
<td>0.8193</td>
<td>61</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Research on New Models | <font color="#90AEE9"> DenseNet | <font color="#6D8AC3"> Test Loss/Accuracy</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[97]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Generate generalization metrics</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test loss: </span><span class="si">{score[0]}</span><span class="s1"> / Test accuracy: </span><span class="si">{score[1]}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test loss: 0.8193304538726807 / Test accuracy: 0.8371999859809875
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Research on New Models | <font color="#90AEE9"> DenseNet | <font color="#6D8AC3"> Plot train/val Loss/Accuracy</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>
<p>The validation score is slightly unstable, but overall shows moderate ovefitting.</p>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[98]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># plot the loss and accuracy</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><font color="#C3D2F2"><strong>Research on New Models | <font color="#90AEE9"> DenseNet | <font color="#6D8AC3"> Confusion Matrix</font></font></strong></font></p><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<hr/>
<p>The confusion matrix shows high percentage of correctly predicted labels and high concentration of values along the diagonal line.</p>

</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></div><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[102]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_images</span><span class="p">)</span>
<span class="n">pred_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">original_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">original_label</span><span class="p">,</span> <span class="n">pred_label</span><span class="p">)</span> 

<span class="n">f</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s2">&quot;gnuplot&quot;</span><span class="p">,</span> <span class="n">linecolor</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.0f&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="c1">#ocean</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea">
<img src="javascript://"/>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&#160;[106]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Class:&quot;</span><span class="p">,</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of Wrong Prediction:&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">-</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">i</span><span class="p">]),</span> <span class="s2">&quot;out of 1000&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Percentage of True Prediction: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="mi">10</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;***********************************************************&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Class: 0
Number of Wrong Prediction: 191 out of 1000
Percentage of True Prediction: 80.90%
***********************************************************
Class: 1
Number of Wrong Prediction: 134 out of 1000
Percentage of True Prediction: 86.60%
***********************************************************
Class: 2
Number of Wrong Prediction: 296 out of 1000
Percentage of True Prediction: 70.40%
***********************************************************
Class: 3
Number of Wrong Prediction: 258 out of 1000
Percentage of True Prediction: 74.20%
***********************************************************
Class: 4
Number of Wrong Prediction: 131 out of 1000
Percentage of True Prediction: 86.90%
***********************************************************
Class: 5
Number of Wrong Prediction: 176 out of 1000
Percentage of True Prediction: 82.40%
***********************************************************
Class: 6
Number of Wrong Prediction: 117 out of 1000
Percentage of True Prediction: 88.30%
***********************************************************
Class: 7
Number of Wrong Prediction: 116 out of 1000
Percentage of True Prediction: 88.40%
***********************************************************
Class: 8
Number of Wrong Prediction: 109 out of 1000
Percentage of True Prediction: 89.10%
***********************************************************
Class: 9
Number of Wrong Prediction: 100 out of 1000
Percentage of True Prediction: 90.00%
***********************************************************
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Class 2 has the lowest number of correctly predicted images: 70.4%. The labels with the highest number of predicted images is Class 9: 90%.
Overall, the DenseNet Model shows a good performance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr/>
<p><strong>END OF ASSIGNMENT TWO</strong></p>

</div>
</div>
</div>
    </font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></div><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
  </font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></div><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">

 


</font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3"><font color="#C3D2F2"><font color="#90AEE9"><font color="#6D8AC3">
</font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font><script type="text/javascript" src="/d2l/common/math/MathML.js?v=20.21.7.30998 "></script><script type="text/javascript">document.addEventListener('DOMContentLoaded', function() { D2LMathML.DesktopInit('https://s.brightspace.com/lib/mathjax/2.7.4/MathJax.js?config=MML_HTMLorMML','https://s.brightspace.com/lib/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML','130',true); });</script></body></html>